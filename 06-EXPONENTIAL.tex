
\setcounter{chapter}{5}
\mychapter{The Exponential Extension}

The two distinctive features of integration in exponential extensions
are the presence of {\it special} polynomials, which divide their own
derivatives, and the appearance of the Risch differential equation.

Let's recall our basic theorem on the behavior of exponential extensions:

\begin{customthm}{\ref{basic exponential properties}}
Let $E=K(\theta)$ be a simple transcendental exponential extension of
a differential field $K$ with the same constant subfield as $K$,
let $p=\sum p_i \theta^i$ be a polynomial in $K[\theta]$ ($p_i \in K$),
and let $r$ be a rational function in $K(\theta)$. Then:

\begin{enumerate}
\item ${\rm Deg}_\theta\, p' = {\rm Deg}_\theta\, p$
\item If $p$ is monic and irreducible, then $p \mid p'$ if and only if $p = \theta$.
\item If an irreducible monic factor other than $\theta$ appears in $r$'s
denominator with multiplicity $m$,
then it appears in $r'$'s denominator with multiplicity $m+1$
\item $r' \in K$ if and only if $r \in K$
\end{enumerate}

\end{customthm}

Contrast this theorem with the behavior of the ordinary polynomials
that we're accustomed to.  Ordinary irreducible polynomials never divide their own derivatives in the
manner described in (2); polynomials that do are called {\it special}.
Instead, ordinary polynomials always behave in the way described in
(3); such polynomials are called {\it normal}.

Irreducible polynomials are characterized as either normal or special,
depending on whether they divide their own their derivatives.
Theorem \ref{basic exponential properties} (2) states that in a
exponential extension, the only special irreducible polynomial is
$\theta$ itself.

\begin{comment}
In a hypertangent extension, the only special
irreducible polynomial is $(\theta^2+1)$.
\end{comment}

We attack integrands in exponential extensions in much the same way as
we attack ordinary polynomials: we factor the denominator into
irreducible factors and perform a partial fractions expansion.  In
this case, however, we have to classify the denominator factors as
either normal or special.  Normal factors can be handled in much the
same way as we're used to, but special factors are treated in a manner
similar to polynomials.

\begin{comment}

t=tan x
t^2+1 = tan^2 x + 1 = sec^2 x
d(t^2+1) = 2tdt = 2 tan x sec^2 x

dt/dx = sec^2 x = (1 + tan^2 x)
Dt = t^2 + 1
D(t^2+1) = 2t(t^2+1)

\end{comment}

For example, let $p=\sum p_i \theta^i$ be a polynomial in $K[\theta]$,
with $\theta = \exp k$,
and take its derivation:

$$p' = \sum_{i=0}^n (p_i' + i p_i k') \theta^i$$

Notice that, unlike the logarithm or rational cases, there is no
interdependence between the various terms of the sum; each term is
completely independent of the others.  Instead, each coefficient of $\theta^i$ has
the form $p_i' + A p_i$, and equating the $p'$ polynomial to the
integrand's polynomial produces a differential equation of the form:

$$p_i' + A p_i = B \qquad A,B,p_i \in K$$

This is called a {\it Risch equation} and is a primary object of our
study.  Solving Risch equations in a differential extension is the
principle problem that we need to solve in order to carry out our
program of symbolic integration.

Special factors in the denominator behave in almost exactly the same
way as polynomials.  They both give rise to Risch equations that need
to be solved in the underlying field.  On the other hand, partial
fractions terms involving normal polynomials give rise to rational
functions and logarithms in the result that can be solved using the
extended Euclidean algorithm, again operating in the underlying field.

We've already studied, in Section \ref{sec:Polynomial Diophantine
Equations}, how to use the extended Euclidean algorithm over an
arbitrary field, so the primary additional tool we need to develop is
the ability to solve Risch equations in arbitrary differential fields,
or at least in the differential fields that arise in the course of our
study.  Once we can do that, we can evaluate integrals in complicated
extension fields by ``peeling away'' the extensions, and solving
equations in successively simplier extensions until we've reached the
rational function field ${\mathbb C}(x)$.

I'll begin by presenting the basic integration theorem for exponential
extensions, then we'll consider how to solve Risch equations
in ${\mathbb C}(x)$, which is a simplified case
that lets us solve integrals in
{\it simple} exponential extensions.  Finally, we'll study
solving the Risch equation more generally.

\vfill\eject
\section{The Exponential Integration Theorem}

\theorem\label{exponential integration theorem}
Let $K$ be a differential field, let $K(\theta = \exp k)$ be a simple
exponential extension of $K$, let $n_i(\theta)$ be
normal irreducible polynomials in $K[\theta]$,
and let $f$ be an element of $K(\theta)$
with partial fractions expansion:

\begin{equation}
\label{exponential integration theorem - integrand}
f = \sum_{i=0}^n a_i \theta^i + \sum_{j=1}^{l} \frac{b_{j}}{\theta^j}
+ \sum_{i=1}^\nu \sum_{j=1}^{m_i} \frac{c_{i,j}(\theta)}{n_i(\theta)^j}
\end{equation}

$$a_i, b_j \in K \qquad c_{i,j}(\theta),n_i(\theta) \in K[\theta]$$

If $f$ has
an elementary anti-derivative $F$, then $F \in K(\theta, \Psi)$,
where $K(\theta, \Psi)$ is a finite logarithm extension
of $K(\theta)$, $F$ has a partial fractions expansion of the form:

\begin{equation}
\label{exponential integration theorem - integral}
F = \sum_{i=0}^n A_i \theta^i + \sum_{j=1}^{l} \frac{B_{j}}{\theta^j}
+ \sum_{i=1}^\nu \sum_{j=1}^{m_i-1} \frac{C_{i,j}(\theta)}{n_i(\theta)^j}
+ \sum_{i=1}^\nu D_i \ln n_i(\theta)
\end{equation}

$$A_i, B_j \in K \qquad C_{i,j}(\theta),n_i(\theta) \in K[\theta] \qquad D_i' = 0$$

and the following relationships hold:

\begin{equation}
\label{eq: exponential A0}
A_0' = a_0 - \sum_{i=1}^\nu D_i \frac{\lc n_i'(\theta)}{\lc n_i(\theta)}
\end{equation}

\begin{equation}
\label{eq: exponential An}
A_i' + i A_i k' = a_i  \qquad  B_{j}' - j k' B_{j} = b_j
\end{equation}

%% \begin{equation}
%% -jC_{i,j}(\theta)n_i'(\theta) = Q_{i,j}(\theta) n_i(\theta) + R_{i,j}(\theta)
%% \end{equation}

\begin{subequations}
\begin{eqnarray}
R_{i,m_i-1}(\theta) & = & c_{i,m_i} \\
R_{i,j-1}(\theta) & = & c_{i,j} - C_{i,j}'(\theta) - Q_{i,j}(\theta) \qquad {}_{1<j\le m_i}
\end{eqnarray}
\end{subequations}

%% $$-jC_{i,j}(\theta)n_i'(\theta) \equiv R_{i,j}(\theta) \mod n_i(\theta)$$

\begin{equation}
C_{i,j}(\theta) \equiv - \frac{R_{i,j}(\theta)}{jn_i'(\theta)} \mod n_i(\theta)
\end{equation}

\begin{equation}
\label{eq: exponential Ds}
D_i = \frac{c_{i,1} - C_{i,1}'(\theta) - Q_{i,1}(\theta)}{n_i'(\theta) - \frac{\lc n_i'(\theta)}{\lc n_i(\theta)} n_i(\theta)}
\end{equation}

\vfill\eject
\proof

% Let's see how to integrate a function $f$ in an exponential extension
% $K(\theta)$, $\theta = \exp(k)$.

By Theorem \ref{weak Liouville theorem}, an elementary antiderivative
of $f$ can only exist in a finite logarithm extension $K(\theta, \Psi)$
of $K(\theta)$ and therefore must have the form:

$$F = R + \sum_{i=1}^\eta D_i \Psi_i$$

where $R \in K(\theta)$, and the $D_i$ are constants.

Constructing a partial fractions expansion of $R$,
separating the normal and special components of its denominator,
and using the fact that $s_1 = \theta$ is the only
special irreducible polynomial
(Theorem \ref{basic exponential properties}):

\begin{comment}
$$F = \sum_{i=0}^N A_i \theta^i + \sum_{i=1}^\mu \sum_{j=1}^{l_i} \frac{B_{ij}(\theta)}{s_i(\theta)^j}
+ \sum_{i=1}^\nu \sum_{j=1}^{m_i} \frac{C_{i,j}(\theta)}{n_i(\theta)^j}
+ \sum_{i=1}^\eta D_i \Psi_i$$

Let's use the fact that $s_1 = \theta$ is the only
special irreducible polynomial:
\end{comment}

$$F = \sum_{i=0}^N A_i \theta^i + \sum_{j=1}^{L} \frac{B_{j}}{\theta^j}
+ \sum_{i=1}^\nu \sum_{j=1}^{M_i} \frac{C_{i,j}(\theta)}{n_i(\theta)^j}
+ \sum_{i=1}^\eta D_i \Psi_i$$

Now let's differentiate, remembering that $\theta' = k'\theta$:

$$F' = \sum_{i=0}^N (A_i' + i A_i k' )\theta^i
  + \sum_{j=1}^{L} \frac{B_{j}' - j k' B_{j}}{\theta^j}
  + \sum_{i=1}^\nu \sum_{j=1}^{M_i} \frac{C_{i,j}'(\theta) n_i(\theta) - j C_{i,j}(\theta) n_i'(\theta) }{n_i(\theta)^{j+1}}
  + \sum_{i=1}^\eta D_i \frac{E_i'(\theta)}{E_i(\theta)}$$

Let's examine the logarithmic elements $E_i(\theta)$.  If an $E_i(\theta)$ doesn't involve $\theta$, i.e, $E_i \in K$,
then we can collapse $D_i \Psi_i$ into $A_0$, with the understanding that when we recurse
into $K$ to solve for $A_0$, additional logarithm terms are allowed.

So now let's consider what happens if $E_i(\theta)$ is a polynomial in $K[\theta]$.  If it's reducible, then
the basic properties of logarithms let us split it into multiple irreducible elements.
Otherwise, it's irreducible and therefore either normal or special.  If it's special, then it
must be $\theta$ itself and $\ln \theta = \ln \exp k = k$, which contracts the
transcendence of the logarithm extension $\Psi$.
So all of the $E_i(\theta)$'s must be normal, and therefore $F'$ must have the form:

\begin{multline*}
F' = A_0' + \sum D_k \frac{E_k'}{E_k} + \sum_{i=1}^N (A_i' + i A_i k' )\theta^i
  + \sum_{j=1}^{L} \frac{B_{j}' - j k' B_{j}}{\theta^j} \\
  + \sum_{i=1}^\nu \sum_{j=1}^{M_i} \frac{C_{i,j}'(\theta) n_i(\theta) - j C_{i,j}(\theta) n_i'(\theta) }{n_i(\theta)^{j+1}}
  + \sum_{i=1}^\eta D_i \frac{n_i(\theta)'}{n_i(\theta)}
\end{multline*}

$F'$ has the form of a partial fractions decomposition, but it is not
a partial fractions decomposition because the numerators in the $C$
and $D$
terms violate the partial fractions degree bounds.  To fix this, let's
divide the $-jC_{i,j}(\theta)n_i'(\theta)$ terms by $n_i(\theta)$
(think polynomial long division) and rewrite them as a quotient
and a remainder:

$$-jC_{i,j}(\theta)n_i'(\theta) = Q_{i,j}(\theta) n_i(\theta) + R_{i,j}(\theta)$$

This fixes the $C$ terms, since $\deg Q_{i,j}(\theta) < \deg n_i(\theta)$
and $\deg R_{i,j}(\theta) < \deg n_i(\theta)$.

We can fix the $D$ terms by noting that $\deg n_i'(\theta) = \deg n_i(\theta)$,
so by subtracting an appropriate multiple of $n_i(\theta)$
we can ensure the cancellation of the leading terms,
achieving our degree bounds.

\begin{multline*}
F' = A_0' + \sum D_k \frac{E_k'}{E_k} + \sum D_i \frac{\lc n_i'(\theta)}{\lc n_i(\theta)} + \sum_{i=1}^N (A_i' + i A_i k' )\theta^i
  + \sum_{j=1}^{L} \frac{B_{j}' - j k' B_{j}}{\theta^j} \\
  + \sum_{i=1}^\nu \Bigg[ \frac{R_{i,M_i}(\theta) }{n_i(\theta)^{M_i+1}}
  + \sum_{j=2}^{M_i} \frac{C_{i,j}'(\theta) + Q_{i,j}(\theta) + R_{i,j-1}(\theta) }{n_i(\theta)^{j}} \\
  + \frac{C_{i,1}'(\theta) + Q_{i,1}(\theta)
  + D_i \left[ n_i(\theta)' - \frac{\lc n_i'(\theta)}{\lc n_i(\theta)} n_i(\theta) \right]}{n_i(\theta)} \Bigg]
\end{multline*}

Now $F'$ is an actual partial fractions decomposition.  It not only has
the right form, but all of the other conditions, specifically
the degree bounds, are met.
Therefore, we can perform
a partial fractions decomposition of $f$:

$$f = \sum_{i=0}^n a_i \theta^i + \sum_{j=1}^{l} \frac{b_{j}}{\theta^j}
+ \sum_{i=1}^\nu \sum_{j=1}^{m_i} \frac{c_{ij}(\theta)}{n_i(\theta)^j}$$

Setting $F' = f$ and equating like terms, we establish that
$n=N$, $l=L$, $M_i+1 = m_i$, and the
relationships listed in the statement of the theorem.  The zero-order term:

$$A_0' + \sum D_k \frac{E_k'}{E_k} + \sum D_i \frac{\lc n_i'(\theta)}{\lc n_i(\theta)} = a_0$$

Polynomial terms
and special denominators give rise to Risch equations:

$$A_i' + i A_i k' = a_i  \qquad  B_{j}' - j k' B_{j} = b_j$$

Normal denominators give rise to these terms:

\begin{align*}
R_{i,m_i}(\theta) & = c_{i,m_i+1} \\
C_{i,j}'(\theta) + Q_{i,j}(\theta) + R_{i,j-1}(\theta) & = c_{i,j} \qquad {}_{1<j\le m_i}\\
C_{i,1}'(\theta) + Q_{i,1}(\theta) + D_i n_i(\theta)' & = c_{i,1}
\end{align*}

Remember the definition of
$R_{i,j}$ and $Q_{i,j}$:

$$-jC_{i,j}(\theta)n_i'(\theta) = Q_{i,j}(\theta) n_i(\theta) + R_{i,j}(\theta)$$

Reducing this equation modulo $n_i(\theta)$, we obtain:

$$-jC_{i,j}(\theta)n_i'(\theta) \equiv R_{i,j}(\theta) \mod n_i(\theta)$$

Now we use the fact that $n_i(\theta)$ is {\it irreducible},
and invoke Theorem ??, which states the quotient ring
modulo a prime ideal is a field, so we can perform division:

$$C_{i,j}(\theta) \equiv - \frac{R_{i,j}(\theta)}{jn_i'(\theta)} \mod n_i(\theta)$$

This equation seems to identify $C_{i,j}(\theta)$ up to a multiple of $n_i(\theta)$,
but if we remember our degree bound on partial fractions expansions,
$\deg_\theta C_{i,j}(\theta) < \deg_\theta n_i(\theta)$, we see
that in fact we've completely determined $C_{i,j}(\theta)$ from
$R_{i,j}(\theta)$.

\endtheorem

We'll begin discussing the Risch equation in the next section, which
is how we obtain the $A_i$'s and $B_i$'s.

How can we calculate the $C_{i,j}(\theta)$'s?

The highest order term in the partial fractions expansion
gives us an $R_{i,j}$ directly.  Then we use
the extended Euclidean algorithm from
Section \ref{sec:Polynomial Diophantine Equations}, which is our major
computational tool for calculating inverses in quotient rings,
to calculate $C_{i,j}(\theta)$.  A simple long division step
then gives us the quotient $Q_{i,j}(\theta)$, and we just
move down the list, solving this system of equations from highest
order terms to lowest.  Once we get to the end, we need to see if the
bottom equation can be solved using a constant $D_i$.  If not,
then the equation has no solution.

Once all of the $D_i$'s have been calculated, then we have all of the
information needed to determine $A_0'$, and an integration step in the
underlying field yields $A_0$ itself.


\begin{comment}
$$F' = \sum_{i=-l}^n (c_i' + i c_i k' )\theta^i
  + \sum_{i=1}^\nu \sum_{j=1}^{m_i} \frac{b_{ij}'(\theta) n_i(\theta) - j b_{ij}(\theta) n_i'(\theta) }{n_i(\theta)^{j+1}}
  + \sum_{i=1}^\eta d_i \frac{n_i(\theta)'}{n_i(\theta)}$$
\end{comment}

\vfil\eject

\example Compute $\int \sin x \, {\rm d}x$

We'll operate in ${\mathbb C}(x, \theta = \exp \,ix)$ and evaluate

$$\int \frac{\theta - \theta^{-1}}{2i} \,dx$$

The first step is write the integrand in partial fractions form:

$$\int \left[ \frac{1}{2i} \theta - \frac{1}{2i} \frac{1}{\theta} \right] \,dx $$

By Theorem \ref{exponential integration theorem}, the integral must have the
form $a_1 \theta + a_{-1} \frac{1}{\theta}$ with $a_1, a_{-1} \in {\mathbb
C}(x)$ and must satisfy the equations:

$$\frac{1}{2i} = a_1' + i a_1 \qquad - \frac{1}{2i} = a_{-1}' - i a_{-1}$$ 

These are very simple Risch equations that can be solved by inspection
to obtain $a_1 = a_{-1} = -\frac{1}{2}$, so

$$\int \frac{\theta - \theta^{-1}}{2i} \,dx = -\frac{1}{2}(\theta + \theta^{-1})
 = -\frac{1}{2}(e^{ix} + e^{-ix}) = -\cos x$$

\endexample

\vfill\eject

\example Compute $\int \csc x \, {\rm d}x$

We'll operate in ${\mathbb C}(x, \phi = \exp \,ix)$ and evaluate

$$\int {{2i}\over{\phi - \phi^{-1}}} \,dx = \int 2i {{\phi}\over{\phi^2 - 1}} \,dx$$

Now we want a partial fractions expansion.  We could use a resultant,
or the Euclidean G.C.D. algorithm, but it's simpler to just note that
the denominator's a difference of squares and compute:

$${{c_1}\over{\phi-1}} + {{c_2}\over{\phi+1}} = {{\phi}\over{\phi^2-1}} $$

$${{c_1}(\phi+1)} + {{c_2}(\phi-1)} = \phi \qquad c_1 = c_2 = {1\over2} $$

giving us

$$\int \left[ {{i}\over{\phi-1}} + {{i}\over{\phi+1}} \right] dx$$

Now we have an integral in the form of equation
\eqref{exponential integration theorem - integrand}
with $\nu=2$, $n_1(\phi) = \phi -1$,
$n_2(\phi) = \phi + 1$,
$m_1=m_2=1$ and $c_{1,1} = c_{2,1} = i$.

$$D_{1} = \frac{c_{1,1}}{n_1'(\theta) - \frac{\lc n_1'(\theta)}{\lc n_1(\theta)} n_1(\theta)} = \frac{i}{i \phi - i (\phi-1)} = 1$$
$$D_{2} = \frac{c_{2,1}}{n_2'(\theta) - \frac{\lc n_2'(\theta)}{\lc n_2(\theta)} n_2(\theta)} = \frac{i}{i \phi - i (\phi+1)} = -1$$

so by Theorem \ref{exponential integration theorem}
the integral can be written:

$$\int \left[ {{i}\over{\phi-1}} + {{i}\over{\phi+1}} \right] dx
= \ln (\phi-1) - \ln(\phi+1) = \ln({{\phi-1}\over{\phi+1}})$$

$$ = \ln ({{e^{ix}-1}\over{e^{ix}+1}}) = \ln ({{e^{ix/2}-e^{-ix/2}}\over{e^{ix/2}+e^{-ix/2}}}) = \ln i {{\sin {x\over2}}\over{\cos {x\over2}}} = \ln \tan {x\over2} $$

where I dropped the $i$ at the end because, as a constant multiple
inside a logarithm, it disappears into the constant of integration,
and we conclude that

$$\int \csc x \,{\rm d}x = \ln \tan {x\over2} $$

\endexample

\vfil\eject

\example Compute $\int \tan x \, {\rm d}x$

We'll operate in ${\mathbb C}(x, \theta = \exp \,ix)$ and evaluate

$$-i \int \frac{\theta - \theta^{-1}}{\theta + \theta^{-1}} \,dx$$

The first step is write the integrand in partial fractions form:

$$\frac{\theta - \theta^{-1}}{\theta + \theta^{-1}} = \frac{\theta^2 - 1}{\theta^2 + 1}
= 1 - \frac{2}{\theta^2 + 1}
= 1 - \frac{2}{(\theta + i)(\theta - i)} $$

$$ = 1 + \frac{i}{\theta - i} - \frac{i}{\theta + i} $$

$$-i\, \frac{\theta - \theta^{-1}}{\theta + \theta^{-1}} = -i + \frac{1}{\theta - i} - \frac{1}{\theta + i} $$

This integrand is now in the form of equation
\eqref{exponential integration theorem - integrand} with
$n_1(\theta) = \theta -i$ and $n_2(\theta) = \theta + i$, $c_{1,1} = 1$,
$c_{2,1}=-1$, $a_0 = 1$ and $k=ix$, so plugging these values
into equation \eqref{eq: exponential Ds}, we obtain:


$$ D_1 = \frac{c_{1,1}}{n_1(\theta)' - \frac{\lc n_1'(\theta)}{\lc n_1(\theta)} n_1(\theta)} = \frac{1}{i \theta - i (\theta -i )} = -1$$
$$ D_2 = \frac{c_{2,1}}{n_2(\theta)' - \frac{\lc n_2'(\theta)}{\lc n_2(\theta)} n_2(\theta)} = \frac{-1}{i \theta - i (\theta +i )} = -1$$

Pluging this into equation \eqref{eq: exponential A0}, we obtain:

$$A_0' = a_0 - \sum_{i=1}^\nu D_i \frac{\lc n_i'(\theta)}{\lc n_i(\theta)}$$
$$A_0' = -i + 2i = i$$
$$A_0 = ix$$

so our integral is:

$$-i \int \frac{\theta - \theta^{-1}}{\theta + \theta^{-1}} \,dx
  = ix - \ln (\theta+i) - \ln(\theta-i)$$
$$  = ix - \ln \left[ (\theta+i)(\theta-i) \right]$$
$$  = ix - \ln \left[ \theta^2 + 1 \right]$$

We can convert this into a more familiar form by realizing 
that $ix = \ln \exp ix = \ln \theta$, so

$$  = \ln \theta - \ln \left[ \theta^2 + 1 \right]
= \ln \frac{\theta}{\theta^2 + 1}
= \ln \frac{1}{\theta^{-1} + \theta}$$

$$\int \tan x \, {\rm d}x = \ln \csc x$$

\endexample

\vfill\eject
\section{Risch Equations in ${\mathbb C}(x)$}

Risch equations in ${\mathbb C}(x)$ arise when our integrand exists in
a {\it simple} exponential extension of ${\mathbb C}(x)$,
i.e, an integrand formed as a rational function of $x$ and a
single exponential of a rational function of $x$.  Theorem
\ref{exponential integration theorem}
then produces Risch equations in the underlying field;
in this case, ${\mathbb C}(x)$.

Consider such a Risch equation:

$$r' + S r = T \qquad S,T,r \in {\mathbb C}(x)$$

\begin{comment}
Recall that in ${\mathbb C}(x)$, irreducible factors in the
denominator always increase in degree on differentiation, so $A$'s
factors are the only factors that can appears in $q$'s denominator,
because they must cancel against $q'$.  Thus, we can easily identify
which irreducible factors can appear in $q$'s denominator, and we next
wish to calculate the multiplicities with which they appear.
\end{comment}

The only poles that can appear in $r$'s denominator must appear in
either $S$ or $T$'s denominator, so let's consider a single pole at
$\gamma$, expand $S$, $T$, and $r$ using partial fractions, and look
at the highest powers of $(x-\gamma)$ in the denominator:

$$r = \frac{a}{(x-\gamma)^j} + \cdots  \qquad  r' = \frac{-ja}{(x-\gamma)^{j+1}} + \cdots$$

$$S = \frac{b}{(x-\gamma)^k} + \cdots$$

$$T = \frac{c}{(x-\gamma)^l} + \cdots$$

Combining everything into the Risch equation, we find:

$$\frac{-ja}{(x-\gamma)^{j+1}} + \cdots + \frac{ba}{(x-\gamma)^{j+k}} + \cdots = \frac{c}{(x-\gamma)^l} + \cdots$$

We can classify the equation into three basic cases, based on the value of $k$:

\begin{enumerate}

\item $k=0$.  In this case, the $\frac{-ja}{(x-\gamma)^{j+1}}$ term dominates the left hand side,
and $j = l-1$ in order to match the right hand side.

\item $k=1$.  Here, the high order terms on the left are equal, so either $j=l-1$ in order to match
the right hand side, or $j=b$ and $j>l-1$ in order for the left hand terms to exactly cancel.

\item $k>1$.  Now the $\frac{ba}{(x-\gamma)^{j+k}}$ term dominates the left hand side, so $j=l-k$ in
order to match the right hand side.

\end{enumerate}

By checking all of $S$'s and $T$'s poles using this technique, we can
identify all the poles in $r$'s denominator and determine the
multiplicity with which they appear.  This determines $r$'s
denominator $d$ completely.

Having done so, we can replace $r$ with $p/d$, which clears the
denominators and produces a polynomial Risch equation:

$$A p' + B p = C \qquad A,B,C,p \in {\mathbb C}[x]$$

There are three cases now.

First, the highest terms on the left can have higher degree than any term on
the right, and so must cancel against each other.  For this to occur,
$\deg A = \deg B + 1$ (since $\deg p$ drops by one on differentiation),
and we can determine $\deg p$ by looking at the leading
coefficients in $A$ and $B$:

$$A = a_j x^j + \cdots \qquad B = b_{j-1} x^{j-1} + \cdots \qquad p = p_k x^k \cdots$$

$$A p' + B p = (k a_j p_k + b_{j-1} p_k) x^{j+k-1} \cdots$$

In order for this coefficient to be zero, $k=-b_{j-1}/a_j$.
So, if these conditions are met:

$$\deg A = \deg B + 1 \qquad k=-\frac{b_{j-1}}{a_j} $$

then $p$ may exist as a $k^{\rm th}$ degree polynomial.

Otherwise, the leading terms of $A p' + B p$ do not cancel out,
so they must match the leading term of $C$.  This can only
occur if

$$\deg p = \deg C - \max(\deg A - 1, \deg B)$$

Having determined the degree of $p$, we can now determine its
coefficients.

The final case we need to consider is when $p$ is a constant, which
would solve the Risch equation if and only if $C$ was a constant
multiple of $B$, irregardless of $A$.

\begin{enumerate}
\item $\deg A = \deg B + 1$ and $\deg p =-\frac{\lc B}{\lc A} $
\item $\deg p = \deg C - \max(\deg A - 1, \deg B)$
\item $p$ is a constant and $pB = C$
\end{enumerate}

\vfill\eject

\example
\label{exp e^{-x^2}}
Prove that $\int e^{-x^2}\, {\rm d}x$ has no elementary form

We'll use ${\mathbb C}(x, \phi = \exp\, -x^2)$, so $\phi' = -2x$ and
study

$$\int \phi \, {\rm d}x$$

We know from Theorem \ref{basic exponential properties} that our
solution, if it exists, must have the form $a\phi$, where $a \in
{\mathbb C}(x)$, and $a$ must satisfy the Risch equation:

$$a' - 2x a = 1$$

This is already a polynomial Risch equation, and $a'$ has only
a constant coefficient, so $a$ can not have a non-trivial denominator.
Futhermore, identifying $A$ as $1$, $B$ as $-2x$, and $C$ as $1$,
we see that $\deg A = 0$ and $\deg B = 1$.  Since $\deg A \ne \deg B + 1$,
the leading terms on the left hand side can not cancel,
so they must match the leading term on the right.
We compute:

$$\deg p = \deg C - \max(\deg A - 1, \deg B) = 0 - 1 = -1$$

so that doesn't work.  Futhermore, $C$ is not a constant
multiple of $B$, so a constant $p$ can't solve our equation.

We conclude that no solution to this Risch equation exists in ${\mathbb C}(x)$,
so the integral can not be expressed in elementary form.

\endexample


\example Prove that $\int \frac{\sin x}{x} \, {\rm d}x$ has no elementary form

As we often do with trigonometric integrals, we'll operate in
${\mathbb C}(x, \phi = \exp \,ix)$, use Euler's relationship
$e^{ix}=i\sin x + \cos x$, and evaluate

$$\int \frac{\phi - \phi^{-1}}{2ix} \,dx$$

Let's begin by writing the integrand in the form of a rational
function in ${\mathbb C}(x)(\phi)$, i.e, a ratio
of $\phi$-polynomials, with coefficients in ${\mathbb C}(x)$:

$$\frac{1}{2i} \int \left[ \frac{1}{x}\phi - \frac{1}{x}\frac{1}{\phi} \right]\,dx$$

\begin{comment}
% This text doesn't belong here
We want to split the denominator into its normal and special
components, by factoring it into irreducible polynomials and
classifying each one as normal or special.  In this case, the
factoriziation is trivial, and we know from theorem \ref{basic
exponential properties} that $\phi$ is special.

Can we have any logarithms in our integral?  Let's see.
Any logarithm of a rational function can be factored and
split into separate logarithms using basic properties
of a logarithms:

$$\ln ab = \ln a + \ln b \qquad\qquad \ln\frac{a}{b} = \ln a - \ln b$$

So, we need only consider logarithms of irreducible polynomials.

Theorem \ref{basic exponential properties} also tells us that we can
have no normal polynomials in denominator of our integral,
\end{comment}


The integral must have the form $a_1 \phi + a_{-1} \frac{1}{\phi}$
with $a_1, a_{-1} \in {\mathbb C}(x)$ and must satisfy the equations:

$$\left[ a_1 \phi + a_{-1}\frac{1}{\phi} \right]' = (a_1' + i a_1 ) \phi + (a_{-1}' - i a_{-1} ) \frac{1}{\phi}
= \left[ \frac{1}{x}\phi - \frac{1}{x}\frac{1}{\phi} \right]$$

$$\frac{1}{x} = a_1' + i a_1 \qquad - \frac{1}{x} = a_{-1}' - i a_{-1}$$

$$a_1' + a_1 = \frac{1}{x}$$

We've got a single pole in the denominator of $T$, so $k=0$, $l=1$,
and $j=l-1=0$, so there are no poles in the denominator of our solution.
However, there is then no way to produce the denominator on the
right, so the Risch equation has no solution in ${\mathbb C}(x)$.


Thus, the integral can not be expressed in elementary form.

\endexample

\vfil\eject

Partial fractions terms involving normal polynomials are handled the
same way as, well, normal polynomials.  Terms with simple denominators
give rise to logarithms in the solution, while terms with higher
powered denominators give rise to rational functions in the solution.

One unusual feature of exponential extensions is that the numerator of
a derivative will have the same degree as the denominator, so a long
division step is needed to make the fraction proper, and this will
produce a constant that will modify the integrand.  For this reason,
it's best to handle the denominator's normal factors first,



\begin{comment}

\vfil\eject

\example Compute $\int {{4^x-1}\over{2^x+1}} {\rm d}x$
\label{integrate 4^x-1/2^x+1}

We'll use the field ${\mathbb C}(x,\Psi = \exp(x \ln 2))$; $\Psi' =
(\ln 2)\Psi$ and the representation (see Example
\ref{represent 4^x+1/2^x+1}):

$$ \frac{\Psi^2-1}{\Psi+1} = \Psi-1$$

So we need to find a solution of the form $a\Psi + \bar{b}$ ($\bar{b}$
can include additional logarithmic elements) that satisfy the Risch
equations:

$$a'\Psi + a\Psi' = a'\Psi + a(\ln 2)\Psi = \Psi \qquad a' + a(\ln 2) = 1$$
$$\bar{b}' = -1$$

Both equations have fairly obvious solutions:

$$a = \frac{1}{\ln 2} \qquad \bar{b}=-x$$

So our solution is

$$\int {{4^x+1}\over{2^x+1}} {\rm d}x = \frac{1}{\ln 2}\Psi - x =
\frac{1}{\ln 2}2^x - x$$

\endexample

\end{comment}

\vfil\eject

\example Compute $\int {{4^x+1}\over{2^x+1}} {\rm d}x$
\label{integrate 4^x+1/2^x+1}

We'll use the field ${\mathbb C}(x,\Psi = \exp(x \ln 2))$; $\Psi' =
(\ln 2)\Psi$ and the representation (see Example
\ref{represent 4^x+1/2^x+1}):

$$ \frac{\Psi^2+1}{\Psi+1} = \Psi-1+\frac{2}{\Psi+1}$$

We'll start, as before, with equation
\eqref{eq: exponential Ds}:

$$ D_1 = \frac{c_{1,1}}{n_1(\theta)' - \frac{\lc n_1'(\theta)}{\lc n_1(\theta)} n_1(\theta)} = \frac{2}{(\ln 2) \Psi - \ln 2 (\Psi +1 )} = -\frac{2}{\ln 2}$$

Now, equation \eqref{eq: exponential An} yields:

$$A_1' + (\ln 2) A_1 = 1 \qquad\Longrightarrow\qquad A_1 = \frac{1}{\ln 2}$$

and equation \eqref{eq: exponential A0} yields:

$$A_0' = a_0 - D_1 \frac{\lc n_i'(\theta)}{\lc n_i(\theta)} = -1 + \frac{2}{\ln 2} \ln 2 = 1$$
$$A_0 = x$$

So our solution is

$$\int {{4^x+1}\over{2^x+1}} {\rm d}x = \frac{1}{\ln 2}\Psi + x  - \frac{2}{\ln 2}\left[\ln(\Psi+1)\right] =
\frac{2^x}{\ln 2} + x - \frac{2}{\ln 2}\ln(2^x+1) $$

\endexample

\vfill\eject

\example
Redo Example \ref{hard log-exp integral} using the exponential theory.

$$\int{{x\{(x^2e^{2x^2}-\ln^2(x+1))^2+2xe^{3x^2}(x-(2x^3+2x^2+x+1)\ln(x+1))\}}\over{(x+1)(\ln^2(x+1) - x^2e^{2x^2})^2}} dx$$

We proceed as before, putting the integral into Liouvillian form
and dividing out $\frac{x}{x+1}$ to obtain a proper fraction:

$$\int {x\over{x+1}} + {{(-4x^5-4x^4-2x^3-2x^2)\psi^3\theta + {2x^3}\psi^3}\over{(x+1)(\theta^2 - x^2\psi^2)^2}} dx$$

This time, we'll operate in ${\mathbb C}(x,\theta = \ln (x+1),\psi = \exp x^2)$, treating
this as an exponential extension of ${\mathbb C}(x,\theta)$.  We'll begin again by
computing a partial fractions expansion, this time with respect to $\psi$:

{\small\begin{verbatim}

(%i1) divide(expand(x*((x^2*p^2-t^2)^2 + 2*x*p^3*(x-(2*x^3+2*x^2+x+1)*t))),
                expand((x+1)*(t^2-x^2*p^2)^2), t);

          x             3  2       3  3      3  4      3  5       3  3
(%o1)  [-----, t ((- 2 p  x ) - 2 p  x  - 4 p  x  - 4 p  x ) + 2 p  x ]
        x + 1

(%i2) partfrac(%o1[2]/((x+1)*(t^2-x^2*p^2)^2), p);

       2     2             2  2      2  3    2     2             2  2      2  3
      t  + (t  - t) x + 2 t  x  + 2 t  x    t  + (t  - t) x + 2 t  x  + 2 t  x
(%o2) ----------------------------------- - -----------------------------------
                     2     2                               2     2
            (t + p x)  (2 x  + 2 x)               (p x - t)  (2 x  + 2 x)
                                   2        3                        2        3
              t + (t - 1) x + 2 t x  + 2 t x    t + (t - 1) x + 2 t x  + 2 t x
            - ------------------------------- - -------------------------------
                                2                                 2
                    (p x + t) (x  + x)                (p x - t) (x  + x)

\end{verbatim}}

\begin{multline*}
\int {x\over{x+1}} + \frac{\frac{2x^3 + 2x^2 + x +1}{2(x^2+x)}\theta^2 - \frac{x}{2(x^2+x)} \theta}{(\theta + x \psi)^2}
       - \frac{\frac{2x^3+2x^2+x+1}{x^2+x}\theta - \frac{x}{x^2+x}}{(\theta + x \psi)} \\
       - \frac{\frac{2x^3 + 2x^2 + x +1}{2(x^2+x)}\theta^2 - \frac{x}{2(x^2+x)} \theta}{(\theta - x \psi)^2}
       + \frac{\frac{2x^3+2x^2+x+1}{x^2+x}\theta - \frac{x}{x^2+x}}{(\theta - x \psi)} dx
\end{multline*}

\begin{multline*}
\int {x\over{x+1}} + \frac{\frac{2x^2 + 1}{2x}\theta^2 - \frac{1}{2(x+1)} \theta}{(\theta + x \psi)^2}
       - \frac{\frac{2x^2+1}{x}\theta - \frac{1}{x+1}}{(\theta + x \psi)} \\
       - \frac{\frac{2x^2 +1}{2x}\theta^2 - \frac{1}{2(x+1)} \theta}{(\theta - x \psi)^2}
       + \frac{\frac{2x^2+1}{x}\theta - \frac{1}{x+1}}{(\theta - x \psi)} dx
\end{multline*}

$n_1(\psi) = \theta + x \psi$ and so

$$c_{1,1}(\psi) = \frac{2x^2+1}{x}\theta - \frac{1}{x+1} \qquad
c_{1,2}(\psi) = \frac{2x^2 + 1}{2x}\theta^2 - \frac{1}{2(x+1)} \theta$$

Now Theorem \ref{exponential integration theorem} tells us
that

$$R_{1,1}(\psi) = c_{1,2}(\psi) = \frac{2x^2 + 1}{2x}\theta^2 - \frac{1}{2(x+1)} \theta$$

$n_1'(\psi) = \frac{1}{x+1} + (1 + 2x^2)\psi$, so

$$C_{1,1}(\psi) = - \frac{R_{1,1}(\psi)}{n_1'(\psi)} \mod n_1(\psi)$$
$$ = - \frac{\frac{2x^2 + 1}{2x}\theta^2 - \frac{1}{2(x+1)} \theta}{\frac{1}{x+1} + (1 + 2x^2)\psi} \mod \theta + x\psi$$

This time, we do need to perform a modulo reduction, but as modulo reductions go, it's
trivial.  Operating $\mod (\theta + x\psi)$ means that we're operating in a field
where $\theta + x\psi = 0$, so $\psi = -\frac{\theta}{x}$.  (EXPLAIN WHY WE'RE
REDUCING w.r.t $\psi$).  Making this substitution, we obtain:

$$ C_{1,1}(\psi) = - \frac{\frac{2x^2 + 1}{2x}\theta^2 - \frac{1}{2(x+1)} \theta}{\frac{1}{x+1} - \frac{1 + 2x^2}{x}\theta} $$
$$ = - \frac{(2x^2 + 1)(x+1)\theta^2 - x \theta}{2x - 2(1 + 2x^2)(x+1)\theta} $$
$$ = \frac{1}{2} \theta $$

Now we wish to compute $Q_{1,1}(\psi)$.  There is no modulo reduction in
this division, and it should always be exact.

$$Q_{1,1}(\psi) = - \frac{R_{1,1}(\theta) + C_{1,1}(\theta) n_1'(\theta)}{n_1(\theta)}$$
$$ = -\frac{\frac{2x^2 + 1}{2x}\theta^2 - \frac{1}{2(x+1)} \theta + \frac{1}{2}\theta \left[\frac{1}{x+1} + (1 + 2x^2)\psi\right]}{\theta + x \psi}$$

$$ = -\frac{\frac{2x^2 + 1}{2x}\theta^2 + \frac{1}{2}\theta \left[(1 + 2x^2)\psi\right]}{\theta + x \psi}
= - \frac{2x^2 + 1}{2x} \theta$$

%% Again substituting $\psi = -\frac{\theta}{x}$ (WHY?), we obtain:

%% $$Q_{1,1}(\psi) = -\frac{\frac{2x^2 + 1}{2x}\theta^2 - \frac{1}{2(x+1)} \theta + \frac{1}{2}\theta \left[\frac{1}{x+1} - (1 + 2x^2)]\frac{\theta}{x}\right]}{\theta + x \psi} = 0$$

Having computed $C_{1,1}$ and $Q_{1,1}$, we are now able to compute $D_1$:

$$ D_1 = \frac{c_{1,1} - C_{1,1}'(\psi) - Q_{1,1}(\psi)}{n_1'(\psi) - \frac{\lc n_1'(\psi)}{\lc n_1(\psi)} n_1(\psi)}$$

$$ D_1 = \frac{- \frac{2x^2+1}{x}\theta + \frac{1}{x+1} - \frac{1}{2}\frac{1}{x+1} + \frac{2x^2 + 1}{2x} \theta}{\frac{1}{x+1} + (1 + 2x^2)\psi - \frac{1+2x^2}{x}(\theta + x \psi)}$$

$$ D_1 = \frac{- \frac{1}{2}(2x^2+1)(x+1)\theta + \frac{1}{2} x}{x + x(x+1)(1 + 2x^2)\psi - (1+2x^2)(x+1)(\theta + x \psi)}$$

$$ D_1 = \frac{- \frac{1}{2}(2x^2+1)(x+1)\theta + \frac{1}{2} x}{x - (1+2x^2)(x+1)\theta} = \frac{1}{2}$$

A similar calculation for $n_2(\psi) = \theta - x \psi$ yields

$$ C_{2,1} = - \frac{1}{2} \theta \qquad D_2 = - \frac{1}{2}$$

In an exponential extension, our $D$ coefficients can affect our $A_0$ term...

$$A_0' = a_0 - \sum_{i=1}^\nu D_i \,\frac{\lc n_1'(\psi)}{\lc n_1(\psi)} $$
$$ = 0 - \frac{1}{2} \frac{(1+2x^2)}{x} + \frac{1}{2} \frac{-(1+2x^2)}{- x} = 0$$

Integrating, we obtain $A_0 = C$, where $C$ is our constant of integration.  We end up with
the same result that we obtained from the logarithmic theory:

$$\int {x\over{x+1}} + {{(-4x^5-4x^4-2x^3-2x^2)\psi^3\theta + {2x^3}\psi^3}\over{(x+1)(\theta^2 - x^2\psi^2)^2}} dx$$
$$= x - \theta + \frac{1}{2}\frac{\theta}{\theta + x \psi} - \frac{1}{2}\frac{\theta}{\theta - x \psi}
+ \frac{1}{2} \ln (\theta + x \psi) - \frac{1}{2} \ln (\theta - x \psi) $$
$$= x - \theta - \frac{x \psi \theta}{\theta^2 - x^2 \psi^2}
+ \frac{1}{2} \ln \frac{\theta + x \psi}{\theta - x \psi}$$


\endexample

\vfill\eject
\section{Risch Equations over Normal Polynomials}

Now let's expand our study to include Risch equations in more
complicated differential fields, starting with normal polynomials,
which will allow us to handle logarithmic extensions.

Consider again such a Risch equation, this time in a simple
transcendental extension $K(\theta)$ of an arbitrary differential
field $K$:

$$r' + S r = T \qquad S,T,r \in K(\theta)$$

Once again, we can perform a partial fractions expansion on $S$, $T$,
and $r$, except that this time our irreducible polynomials are more
complicated that $(x-\gamma)$.  Consider one such normal irreducible
polynomial $n(\theta)$:

$$S = \frac{b(\theta)}{n(\theta)^k} + \cdots
\qquad T = \frac{c(\theta)}{n(\theta)^l} + \cdots$$

$$r = \frac{a(\theta)}{n(\theta)^j} + \cdots  \qquad
r' = \frac{a'(\theta)n(\theta)-ja(\theta)n'(\theta)}{n(\theta)^{j+1}} + \cdots = \frac{-ja(\theta)n'(\theta)}{n(\theta)^{j+1}} + \cdots$$

Plugging this all into the Risch equation, we obtain:

$$\frac{-ja(\theta)n'(\theta)}{n(\theta)^{j+1}} + \cdots + \frac{a(\theta) b(\theta)}{n(\theta)^{j+k}} + \cdots = \frac{c(\theta)}{n(\theta)^l} + \cdots$$

Both of the numerators on the left hand side could have $\theta$-degree greater than $\deg_\theta n(\theta)$,
so we divide them by $n(\theta)$:

% Dividing the numerator of $r'$ by $n(\theta)$, we obtain:

% $$-ja(\theta)n'(\theta) = Q(\theta) n(\theta) + R_1(\theta)$$

$$R_1(\theta) = -ja(\theta)n'(\theta) \mod n(\theta)$$
$$R_2(\theta) = a(\theta)b(\theta) \mod n(\theta)$$

% $$r = \frac{a(\theta)}{n(\theta)^j} + \cdots  \qquad  r' = \frac{R_1(\theta)}{n(\theta)^{j+1}} + \cdots$$

% Plugging this all into the Risch equation, we obtain:

$$\frac{R_1(\theta)}{n(\theta)^{j+1}} + \frac{R_2(\theta)}{n(\theta)^{j+k}} = \frac{c(\theta)}{n(\theta)^l}$$

% $$R_2(\theta) = a(\theta)b(\theta) \mod n(\theta)$$

Since $n(\theta)$ is irreducible, $K/(n_i)$ is a field, so it has no zero divisors, and
neither $R_1(\theta)$ and $R_2(\theta)$ are zero.

Our three cases are as before, except that when $k=1$, our cancellation condition becomes:

$$R_1(\theta) = -R_2(\theta) \mod n(\theta)$$

$$ja(\theta)n'(\theta) = a(\theta)b(\theta) \mod n(\theta)$$

Again, division is possible in a field, so

$$j = \frac{b(\theta)}{n'(\theta)} \mod n(\theta)$$

Our three cases become:

\begin{enumerate}

\item $k=0$ and $j = l-1$.

\item $k=1$ and either $j=l-1$ or $j = \frac{b(\theta)}{n'(\theta)} \mod n(\theta)$.

\item $k>1$ and $j=l-k$.

\end{enumerate}

Once we have determined the factors and multiplicities in the denominator,
then we can proceed as before, clearing out the denominator and obtaining
a polynomial equation.

\vfill\eject

\example Determine if $\int x^x dx$ has an elementary form.

To handle this integral, we'll rewrite it as $\int e^{x \ln x} dx$
and operate in the field ${\mathbb C}(\theta, \psi)$, where
$\theta = \ln x$ and $\psi = \exp x\theta$.  So, we're
trying to compute

$$\int \psi\, dx$$

Applying theorem \ref{exponential integration theorem}, we
obtain the following Risch equation in
${\mathbb C}(\theta)$:

$$A_1' + k' A_1 = 1$$

$$A_1' + (\theta + 1) A_1 = 1$$

$$A=1 \qquad B=\theta +1 \qquad C=1$$

Since $\deg A = 0$ and $\deg B=1$, $\deg A \ne \deg B + 1$,
so we can't have cancellation on the left hand side.
This means that

$$\deg A_1 = \deg C - \max(\deg A - 1, \deg B) = 0 - \max(-1, 1) = -1$$

which is impossible.  The only remaining case to consider
is if $A_1$ is constant, which is also impossible.

We conclude that this Risch equation has no solution
in ${\mathbb C}(\theta)$, and that the original integral
is not elementary.

\endexample

\vfill\eject
\section{Risch Equations over Special Polynomials}

Finally, let's consider Risch equations over fields
with special polynomials, i.e, exponential extensions
with $\theta = \exp k$ and $\theta' = k' \theta$.

$$r' + S r = T \qquad S,T,r \in K(\theta)$$

First, what happens when our partial
fractions decomposition yields special polynomials
in the denominators of $S$ or $T$?

$$S = \frac{b}{\theta^k} + \cdots \qquad T = \frac{c}{\theta^l} + \cdots \qquad b,c \in K$$


%% $$r = \frac{a(\theta)}{n(\theta)^j} + \cdots  \qquad  r' = \frac{-ja(\theta)n'(\theta) + a'(\theta)n(\theta)}{n(\theta)^{j+1}} + \cdots$$

%% $$r = \frac{a(\theta)}{n(\theta)^j} + \cdots  \qquad  r' = \frac{-ja(\theta)\frac{n'(\theta)}{n(\theta)} + a'(\theta)}{n(\theta)^{j}} + \cdots$$

$$r = \frac{a}{\theta^j} + \cdots  \qquad  r' = \frac{-j k' a + a'}{\theta^{j}} + \cdots \qquad a \in K$$

First, we should consider if the leading $r'$ term actually exists.
Could the numerator actually be zero?  If so, then $j k' a = a'$,
but this could only happen if $a$ were a constant
multiple of $\theta^j$ (PROVE THIS), which contradicts the
transcendance of $\theta$ over $K$.

Our Risch equation becomes:

$$\frac{-j k' a + a'}{\theta^{j}} + \cdots + \frac{a b }{\theta^{k+j}} + \cdots
= \frac{c}{\theta^l} + \cdots$$

There are two cases:

\begin{enumerate}
\item $k=0$ and either $j=l$ or
%% $-j k' a + a' + b c = 0$, so
$j = \frac{a' + b c}{k' a}$
%% (assuming that this fraction is an integer).
\item $k>0$ and $j=l-k$.
\end{enumerate}

Now we have computed $j$, the multiplicity of the special factor
$\theta$ in the
denominator, and our normal theory from the previous section gives us
the denominator multiplicity of our normal factors, so
we've computed $d$, the denominator of $r$, and
thus can replace $r$ with $p/d$, which will
yield a polynomial Risch equation.

There are additional issues that arises with special polynomials when
solving a polynomial Risch equation:

$$A r' + B r = C \qquad A,B,C \in K[\theta] \quad r \in K(\theta)$$

If $K[\theta]$ has only normal polynomials, then this equation can be
solved as described before, since $r$ must be a polynomial.
In the special case, however, $r$ could have a special denominator.
Expanding as before...

$$r = \frac{a}{\theta^j} + \cdots  \qquad  r' = \frac{-j k' a + a'}{\theta^{j}} + \cdots$$

If $A$ and $B$ have no $\theta$ factors, then their zeroth order coefficients will produce $j$-th order fractions:

$$ A(0) \frac{-j k' a + a'}{\theta^{j}} + \cdots
+ B(0) \frac{a}{\theta^j} + \cdots  = C$$

Since $C$ is a polynomial, the fractions on the left must cancel, and we obtain:

$$\left[ -j a k' + a' \right] A(0) + a B(0) = 0$$

%% $$j = \frac{a(\theta) B(0) - a'(\theta) A(0)}{a(\theta)k'}$$

%%$$\left[ jk' + \frac{a'(\theta)}{a(\theta) } \right] = \frac{B(0)}{A(0)}$$
$$ jk' - \frac{a'}{a }  = \frac{B(0)}{A(0)}$$

Integrating, we obtain:

$$ jk - \ln a = \int \frac{B(0)}{A(0)} dx$$

We don't know $a$, but $A$, $B$, and $k$ are all known, so solving
this equation amounts to an integration step that must result in a
constant multiple of $k$ plus a possible logarithm.

This completes our determination of the denominator of $r$, and we
are now reduced to a polynomial equation:

$$A p' + B p = C \qquad A,B,C,p \in K[\theta]$$

$$p = p_n \theta^n + \cdots \qquad p' = (p_n' + n p_n k') \theta^n + \cdots$$

So the leading term on the left hand side is:

$$\lc A (p_n' + n p_n k') + \lc B p_n = 0$$

$$n k' + \frac{p_n'}{p_n} = - \frac{\lc B}{\lc A}$$

This equation has the same form as ?, so again, we integrate:

$$n k + \ln p_n = - \int \frac{\lc B}{\lc A} dx$$

\vfill\eject

\example (Bronstein examples 6.2.1, 6.3.3, 6.4.2) Integrate
$$\int \frac{e^x - x^2 + 2x}{(e^x + x)^2 x^2}e^{(x^2-1)/(x+1)/(e^x+x)} dx$$

$$\int \frac{e^x - x^2 + 2x}{(e^x + x)^2 x^2}e^{(x-1)/(e^x+x)} dx$$

We'll use the differential field ${\mathbb C}(\theta, \psi)$ where
$\theta = \exp x$ and $\psi = \exp \frac{x-1}{\theta+x}$.

$$\int \frac{\theta - x^2 + 2x}{(\theta + x)^2 x^2} \psi dx$$

$k = \frac{x-1}{\theta+x}$ so
$k' = \frac{(\theta+x) - (x-1)(\theta+1)}{(\theta+x)^2} = \frac{-x\theta + 2 \theta +1}{(\theta+x)^2}$.
Equation ? gives:

$$A_1' + \frac{-x\theta + 2 \theta +1}{(\theta+x)^2} A_1 = \frac{\theta - x^2 + 2x}{(\theta + x)^2 x^2}$$

$(\theta+x)$ is a normal polynomial, so our normal theory tells us that
since $k=2$ and $l=2$, then $j=l-k=0$, so $(\theta+x)$ does not appear
in the denominator of $A_1$.  Likewise, $x$ is a normal polynomial
for which $k=0$ and $l=2$, so $j=l-1 = 1$, and $x$ can appear in
$A_1$'s denominator.  Writing:

$$A_1 = \frac{S_1}{x} \qquad A_1' = \frac{S_1' x - S_1}{x^2}$$

and substituting:

$$\frac{S_1' x - S_1}{x^2} + \frac{-x\theta + 2 \theta +1}{(\theta+x)^2} \frac{S_1}{x} = \frac{\theta - x^2 + 2x}{(\theta + x)^2 x^2}$$

$$(\theta+x)^2 (S_1' x - S_1) + x S_1(-x\theta + 2 \theta +1) = \theta - x^2 + 2x$$

$$(\theta+x)^2 (S_1' x - S_1) + (-x^2\theta + 2 x \theta + x) S_1 = \theta - x^2 + 2x$$

$$(\theta+x)^2 x S_1' + (-\theta^2 -x^2\theta - x^2 + x) S_1 = \theta - x^2 + 2x$$

$$A = (\theta+x)^2 x \qquad B = (-\theta^2 -x^2\theta - x^2 + x) \qquad C = \theta - x^2 + 2x$$

Can we have cancelation?  To determine if so, we need to integrate:

$$\int \frac{B(0)}{A(0)} dx = \int \frac{-x^2+x}{x^3} dx = - \ln x - \frac{1}{x}$$

This does not have the form $jk + \ln a(\theta)$, where $k=x$, so cancellation
can not occur and we conclude that we have no special denominator.

Now we're reduced to solving a purely polynomial Risch equation over ${\mathbb C}(\theta)$:

$$(\theta+x)^2 x P_1' + (-\theta^2 -x^2\theta - x^2 + x) P_1 = \theta - x^2 + 2x$$

$$A = (\theta+x)^2 x \qquad B = (-\theta^2 -x^2\theta - x^2 + x) \qquad C = \theta - x^2 + 2x$$

Can cancellation occur now?  We integrate:

$$- \int \frac{\lc B}{\lc A} dx = \int \frac{x^2+1}{x} dx = \frac{1}{2}x^2 + \ln x$$



\endexample

\begin{comment}
\vfill\eject

Consider an irreducible factor $F$ that appears both as a factor of $A$
and also in $q$'s denominator, with
multiplicity $m \ge 1 $, so $q = N/(F^m D)$, and we rewrite the Risch equation:

$$A F q' - B q = C$$

$$A F \frac{N' F D - m N F' D - N F D'}{F^{m+1} D^2} - B \frac{N}{F^m D} = C$$

$$A F N' D - m A F' N D - A F N D' - B N D = C D^2 F^{m}$$

$$ - m A F' N D - B N D  = C D^2 F^{m} - A F N' D + A F N D'$$

$$ - (m A F' - B ) N D  = F (C D^2 F^{m-1} - A N' D - A N D')$$

Now, the right hand side of this equation is a multiple of $F$, so the
left hand side must also be a multiple of $F$.  However, $F$ is
irreducible and is relatively prime to both $N$ and $D$, so the only way
the left hand side can be a multiple of $F$ is if $m A F' - B$ is a
multiple of $F$.

Why?  All of these variables
are polynomials in ${\mathbb C}[x]$, so this equation is an equality
between polynomials.  Because ${\mathbb C}[x]$ is a {\it unique factorization domain}, its
polynomials can factor in essentially one way only, so if $F$ factors
the right hand side, it must also factor the left.  If $F$ were not
irreducible, then it might have two factors, one contributed by $N$
and the other contributed by $D$.  It's the irreducibility of $F$,
the unique factorization of polynomials in ${\mathbb C}[x]$, and
our assumption that $N$ and $D$ are relatively prime to $F$
that makes this argument work.

The simplest way to enforce this factorization requirement is to use
the resultant (Theorem \ref{resultant theorem}):

$${\rm res}_x(m A F' - B, F) = 0$$

We calculate this resultant for each irreducible factor $F$ of $A$,
and this gives us $m$, the power to which $F$ appears in $q$'s
denominator.  If this resultant equation has no positive integer
solution, then $F$ can not appear at all in $q$'s denominator.

\end{comment}
