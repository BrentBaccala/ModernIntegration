
\setcounter{chapter}{5}
\mychapter{The Exponential Extension}

The two distinctive features of integration in exponential extensions
are the presence of {\it special} polynomials, which divide their own
derivatives, and the appearance of the Risch differential equation.

Let's recall our basic theorem on the behavior of exponential extensions:

\begin{customthm}{\ref{basic exponential properties}}
Let $E=K(\theta)$ be a simple transcendental exponential extension of
a differential field $K$ with the same constant subfield as $K$,
let $p=\sum p_i \theta^i$ be a polynomial in $K[\theta]$ ($p_i \in K$),
and let $r$ be a rational function in $K(\theta)$. Then:

\begin{enumerate}
\item ${\rm Deg}_\theta\, p' = {\rm Deg}_\theta\, p$
\item If $p$ is monic and irreducible, then $p \mid p'$ if and only if $p = \theta$.
\item If an irreducible monic factor other than $\theta$ appears in $r$'s
denominator with multiplicity $m$,
then it appears in $r'$'s denominator with multiplicity $m+1$
\item $r' \in K$ if and only if $r \in K$
\end{enumerate}

\end{customthm}

Contrast this theorem with the behavior of the ordinary polynomials
that we're accustomed to.  Ordinary irreducible polynomials never divide their own derivatives in the
manner described in (2); polynomials that do are called {\it special}.
Instead, ordinary polynomials always behave in the way described in
(3); such polynomials are called {\it normal}.

Irreducible polynomials are characterized as either normal or special,
depending on whether they divide their own their derivatives.
Theorem \ref{basic exponential properties} (2) states that in a
exponential extension, the only special irreducible polynomial is
$\theta$ itself.

\begin{comment}
In a hypertangent extension, the only special
irreducible polynomial is $(\theta^2+1)$.
\end{comment}

We attack integrands in exponential extensions in much the same way as
we attack ordinary polynomials: we factor the denominator into
irreducible factors and perform a partial fractions expansion.  In
this case, however, we have to classify the denominator factors as
either normal or special.  Normal factors can be handled in much the
same way as we're used to, but special factors are treated in a manner
similar to polynomials.

\begin{comment}

t=tan x
t^2+1 = tan^2 x + 1 = sec^2 x
d(t^2+1) = 2tdt = 2 tan x sec^2 x

dt/dx = sec^2 x = (1 + tan^2 x)
Dt = t^2 + 1
D(t^2+1) = 2t(t^2+1)

\end{comment}

For example, let $p=\sum p_i \theta^i$ be a polynomial in $K[\theta]$,
with $\theta = \exp k$,
and take its derivation:

$$p' = \sum_{i=0}^n (p_i' + i p_i k') \theta^i$$

Notice that, unlike the logarithm or rational cases, there is no
interdependence between the various terms of the sum; each term is
completely independent of the others.  Instead, each coefficient of $\theta^i$ has
the form $p_i' + A p_i$, and equating the $p'$ polynomial to the
integrand's polynomial produces a differential equation of the form:

$$p_i' + A p_i = B \qquad A,B,p_i \in K$$

This is called a {\it Risch equation} and is a primary object of our
study.  Solving Risch equations in a differential extension is the
principle problem that we need to solve in order to carry out our
program of symbolic integration.

Special factors in the denominator behave in almost exactly the same
way as polynomials.  They both give rise to Risch equations that need
to be solved in the underlying field.  On the other hand, partial
fractions terms involving normal polynomials give rise to rational
functions and logarithms in the result that can be solved using the
extended Euclidean algorithm, again operating in the underlying field.

We've already studied, in Section \ref{sec:Polynomial Diophantine
Equations}, how to use the extended Euclidean algorithm over an
arbitrary field, so the primary additional tool we need to develop is
the ability to solve Risch equations in arbitrary differential fields,
or at least in the differential fields that arise in the course of our
study.  Once we can do that, we can evaluate integrals in complicated
extension fields by ``peeling away'' the extensions, and solving
equations in successively simplier extensions until we've reached the
rational function field ${\mathbb C}(x)$.

I'll begin by presenting the basic integration theorem for exponential
extensions, then we'll consider how to solve Risch equations
in ${\mathbb C}(x)$, which is a simplified case
that lets us solve integrals in
{\it simple} exponential extensions.  Finally, we'll study
solving the Risch equation more generally.

\vfill\eject
\section{The Exponential Integration Theorem}

\theorem\label{exponential integration theorem}
Let $K$ be a differential field, let $K(\theta = \exp k)$ be a simple
exponential extension of $K$, let $n_i(\theta)$ be
normal irreducible polynomials in $K[\theta]$,
and let $f$ be an element of $K(\theta)$
with partial fractions expansion:

\begin{equation}
\label{exponential integration theorem - integrand}
f = \sum_{i=0}^n a_i \theta^i + \sum_{j=1}^{l} \frac{b_{j}}{\theta^j}
+ \sum_{i=1}^\nu \sum_{j=1}^{m_i} \frac{c_{i,j}(\theta)}{n_i(\theta)^j}
\end{equation}

$$a_i, b_j \in K \qquad c_{i,j}(\theta),n_i(\theta) \in K[\theta]$$

If $f$ has
an elementary anti-derivative $F$, then $F \in K(\theta, \Psi)$,
where $K(\theta, \Psi)$ is a finite logarithm extension
of $K(\theta)$, $F$ has a partial fractions expansion of the form:

\begin{equation}
\label{exponential integration theorem - integral}
F = \sum_{i=0}^n A_i \theta^i + \sum_{j=1}^{l} \frac{B_{j}}{\theta^j}
+ \sum_{i=1}^\nu \sum_{j=1}^{m_i-1} \frac{C_{i,j}(\theta)}{n_i(\theta)^j}
+ \sum_{i=1}^\nu D_i \ln n_i(\theta)
\end{equation}

$$A_i, B_j \in K \qquad C_{i,j}(\theta),n_i(\theta) \in K[\theta] \qquad D_i' = 0$$

and the following relationships hold:

\begin{equation}
\label{eq: exponential A0}
A_0' = a_0 - \sum_{i=1}^\nu D_i \frac{\lc n_i'(\theta)}{\lc n_i(\theta)}
\end{equation}

\begin{equation}
\label{eq: exponential An}
A_i' + i A_i k' = a_i  \qquad  B_{j}' - j k' B_{j} = b_j
\end{equation}

%% \begin{equation}
%% -jC_{i,j}(\theta)n_i'(\theta) = Q_{i,j}(\theta) n_i(\theta) + R_{i,j}(\theta)
%% \end{equation}

\begin{subequations}
\begin{eqnarray}
R_{i,m_i-1}(\theta) & = & c_{i,m_i} \\
R_{i,j-1}(\theta) & = & c_{i,j} - C_{i,j}'(\theta) - Q_{i,j}(\theta) \qquad {}_{1<j\le m_i}
\end{eqnarray}
\end{subequations}

%% $$-jC_{i,j}(\theta)n_i'(\theta) \equiv R_{i,j}(\theta) \mod n_i(\theta)$$

\begin{equation}
C_{i,j}(\theta) \equiv - \frac{R_{i,j}(\theta)}{jn_i'(\theta)} \mod n_i(\theta)
\end{equation}

\begin{equation}
\label{eq: exponential Ds}
D_i = \frac{c_{i,1} - C_{i,1}'(\theta) - Q_{i,1}(\theta)}{n_i'(\theta) - \frac{\lc n_i'(\theta)}{\lc n_i(\theta)} n_i(\theta)}
\end{equation}

\vfill\eject
\proof

% Let's see how to integrate a function $f$ in an exponential extension
% $K(\theta)$, $\theta = \exp(k)$.

By Theorem \ref{weak Liouville theorem}, an elementary antiderivative
of $f$ can only exist in a finite logarithm extension $K(\theta, \Psi)$
of $K(\theta)$ and therefore must have the form:

$$F = R + \sum_{i=1}^\eta D_i \Psi_i$$

where $R \in K(\theta)$, and the $D_i$ are constants.

Constructing a partial fractions expansion of $R$,
separating the normal and special components of its denominator,
and using the fact that $s_1 = \theta$ is the only
special irreducible polynomial
(Theorem \ref{basic exponential properties}):

\begin{comment}
$$F = \sum_{i=0}^N A_i \theta^i + \sum_{i=1}^\mu \sum_{j=1}^{l_i} \frac{B_{ij}(\theta)}{s_i(\theta)^j}
+ \sum_{i=1}^\nu \sum_{j=1}^{m_i} \frac{C_{i,j}(\theta)}{n_i(\theta)^j}
+ \sum_{i=1}^\eta D_i \Psi_i$$

Let's use the fact that $s_1 = \theta$ is the only
special irreducible polynomial:
\end{comment}

$$F = \sum_{i=0}^N A_i \theta^i + \sum_{j=1}^{L} \frac{B_{j}}{\theta^j}
+ \sum_{i=1}^\nu \sum_{j=1}^{M_i} \frac{C_{i,j}(\theta)}{n_i(\theta)^j}
+ \sum_{i=1}^\eta D_i \Psi_i$$

Now let's differentiate, remembering that $\theta' = k'\theta$:

$$F' = \sum_{i=0}^N (A_i' + i A_i k' )\theta^i
  + \sum_{j=1}^{L} \frac{B_{j}' - j k' B_{j}}{\theta^j}
  + \sum_{i=1}^\nu \sum_{j=1}^{M_i} \frac{C_{i,j}'(\theta) n_i(\theta) - j C_{i,j}(\theta) n_i'(\theta) }{n_i(\theta)^{j+1}}
  + \sum_{i=1}^\eta D_i \frac{E_i'(\theta)}{E_i(\theta)}$$

Let's examine the logarithmic elements $E_i(\theta)$.  If an $E_i(\theta)$ doesn't involve $\theta$, i.e, $E_i \in K$,
then we can collapse $D_i \Psi_i$ into $A_0$, with the understanding that when we recurse
into $K$ to solve for $A_0$, additional logarithm terms are allowed.

So now let's consider what happens if $E_i(\theta)$ is a polynomial in $K[\theta]$.  If it's reducible, then
the basic properties of logarithms let us split it into multiple irreducible elements.
Otherwise, it's irreducible and therefore either normal or special.  If it's special, then it
must be $\theta$ itself and $\ln \theta = \ln \exp k = k$, which contracts the
transcendence of the logarithm extension $\Psi$.
So all of the $E_i(\theta)$'s must be normal, and therefore $F'$ must have the form:

\begin{multline*}
F' = A_0' + \sum D_k \frac{E_k'}{E_k} + \sum_{i=1}^N (A_i' + i A_i k' )\theta^i
  + \sum_{j=1}^{L} \frac{B_{j}' - j k' B_{j}}{\theta^j} \\
  + \sum_{i=1}^\nu \sum_{j=1}^{M_i} \frac{C_{i,j}'(\theta) n_i(\theta) - j C_{i,j}(\theta) n_i'(\theta) }{n_i(\theta)^{j+1}}
  + \sum_{i=1}^\eta D_i \frac{n_i(\theta)'}{n_i(\theta)}
\end{multline*}

$F'$ has the form of a partial fractions decomposition, but it is not
a partial fractions decomposition because the numerators in the $C$
and $D$
terms violate the partial fractions degree bounds.  To fix this, let's
divide the $-jC_{i,j}(\theta)n_i'(\theta)$ terms by $n_i(\theta)$
(think polynomial long division) and rewrite them as a quotient
and a remainder:

$$-jC_{i,j}(\theta)n_i'(\theta) = Q_{i,j}(\theta) n_i(\theta) + R_{i,j}(\theta)$$

This fixes the $C$ terms, since $\deg Q_{i,j}(\theta) < \deg n_i(\theta)$
and $\deg R_{i,j}(\theta) < \deg n_i(\theta)$.

We can fix the $D$ terms by noting that $\deg n_i'(\theta) = \deg n_i(\theta)$,
so by subtracting an appropriate multiple of $n_i(\theta)$
we can ensure the cancellation of the leading terms,
achieving our degree bounds.

\begin{multline*}
F' = A_0' + \sum D_k \frac{E_k'}{E_k} + \sum D_i \frac{\lc n_i'(\theta)}{\lc n_i(\theta)} + \sum_{i=1}^N (A_i' + i A_i k' )\theta^i
  + \sum_{j=1}^{L} \frac{B_{j}' - j k' B_{j}}{\theta^j} \\
  + \sum_{i=1}^\nu \Bigg[ \frac{R_{i,M_i}(\theta) }{n_i(\theta)^{M_i+1}}
  + \sum_{j=2}^{M_i} \frac{C_{i,j}'(\theta) + Q_{i,j}(\theta) + R_{i,j-1}(\theta) }{n_i(\theta)^{j}} \\
  + \frac{C_{i,1}'(\theta) + Q_{i,1}(\theta)
  + D_i \left[ n_i(\theta)' - \frac{\lc n_i'(\theta)}{\lc n_i(\theta)} n_i(\theta) \right]}{n_i(\theta)} \Bigg]
\end{multline*}

Now $F'$ is an actual partial fractions decomposition.  It not only has
the right form, but all of the other conditions, specifically
the degree bounds, are met.
Therefore, we can perform
a partial fractions decomposition of $f$:

$$f = \sum_{i=0}^n a_i \theta^i + \sum_{j=1}^{l} \frac{b_{j}}{\theta^j}
+ \sum_{i=1}^\nu \sum_{j=1}^{m_i} \frac{c_{ij}(\theta)}{n_i(\theta)^j}$$

Setting $F' = f$ and equating like terms, we establish that
$n=N$, $l=L$, $M_i+1 = m_i$, and the
relationships listed in the statement of the theorem.  The zero-order term:

$$A_0' + \sum D_k \frac{E_k'}{E_k} + \sum D_i \frac{\lc n_i'(\theta)}{\lc n_i(\theta)} = a_0$$

Polynomial terms
and special denominators give rise to Risch equations:

$$A_i' + i A_i k' = a_i  \qquad  B_{j}' - j k' B_{j} = b_j$$

Normal denominators give rise to these terms:

\begin{align*}
R_{i,m_i}(\theta) & = c_{i,m_i+1} \\
C_{i,j}'(\theta) + Q_{i,j}(\theta) + R_{i,j-1}(\theta) & = c_{i,j} \qquad {}_{1<j\le m_i}\\
C_{i,1}'(\theta) + Q_{i,1}(\theta) + D_i n_i(\theta)' & = c_{i,1}
\end{align*}

Remember the definition of
$R_{i,j}$ and $Q_{i,j}$:

$$-jC_{i,j}(\theta)n_i'(\theta) = Q_{i,j}(\theta) n_i(\theta) + R_{i,j}(\theta)$$

Reducing this equation modulo $n_i(\theta)$, we obtain:

$$-jC_{i,j}(\theta)n_i'(\theta) \equiv R_{i,j}(\theta) \mod n_i(\theta)$$

Now we use the fact that $n_i(\theta)$ is {\it irreducible},
and invoke Theorem ??, which states the quotient ring
modulo a prime ideal is a field, so we can perform division:

$$C_{i,j}(\theta) \equiv - \frac{R_{i,j}(\theta)}{jn_i'(\theta)} \mod n_i(\theta)$$

This equation seems to identify $C_{i,j}(\theta)$ up to a multiple of $n_i(\theta)$,
but if we remember our degree bound on partial fractions expansions,
$\deg_\theta C_{i,j}(\theta) < \deg_\theta n_i(\theta)$, we see
that in fact we've completely determined $C_{i,j}(\theta)$ from
$R_{i,j}(\theta)$.

\endtheorem

We'll begin discussing the Risch equation in the next section, which
is how we obtain the $A_i$'s and $B_i$'s.

How can we calculate the $C_{i,j}(\theta)$'s?

The highest order term in the partial fractions expansion
gives us an $R_{i,j}$ directly.  Then we use
the extended Euclidean algorithm from
Section \ref{sec:Polynomial Diophantine Equations}, which is our major
computational tool for calculating inverses in quotient rings,
to calculate $C_{i,j}(\theta)$.  A simple long division step
then gives us the quotient $Q_{i,j}(\theta)$, and we just
move down the list, solving this system of equations from highest
order terms to lowest.  Once we get to the end, we need to see if the
bottom equation can be solved using a constant $D_i$.  If not,
then the equation has no solution.

Once all of the $D_i$'s have been calculated, then we have all of the
information needed to determine $A_0'$, and an integration step in the
underlying field yields $A_0$ itself.


\begin{comment}
$$F' = \sum_{i=-l}^n (c_i' + i c_i k' )\theta^i
  + \sum_{i=1}^\nu \sum_{j=1}^{m_i} \frac{b_{ij}'(\theta) n_i(\theta) - j b_{ij}(\theta) n_i'(\theta) }{n_i(\theta)^{j+1}}
  + \sum_{i=1}^\eta d_i \frac{n_i(\theta)'}{n_i(\theta)}$$
\end{comment}

\vfil\eject

\example Compute $\int \sin x \, {\rm d}x$

We'll operate in ${\mathbb C}(x, \theta = \exp \,ix)$ and evaluate

$$\int \frac{\theta - \theta^{-1}}{2i} \,dx$$

The first step is write the integrand in partial fractions form:

$$\int \left[ \frac{1}{2i} \theta - \frac{1}{2i} \frac{1}{\theta} \right] \,dx $$

By Theorem \ref{exponential integration theorem}, the integral must have the
form $a_1 \theta + a_{-1} \frac{1}{\theta}$ with $a_1, a_{-1} \in {\mathbb
C}(x)$ and must satisfy the equations:

$$\frac{1}{2i} = a_1' + i a_1 \qquad - \frac{1}{2i} = a_{-1}' - i a_{-1}$$ 

These are very simple Risch equations that can be solved by inspection
to obtain $a_1 = a_{-1} = -\frac{1}{2}$, so

$$\int \frac{\theta - \theta^{-1}}{2i} \,dx = -\frac{1}{2}(\theta + \theta^{-1})
 = -\frac{1}{2}(e^{ix} + e^{-ix}) = -\cos x$$

\endexample

\vfill\eject

\example Compute $\int \csc x \, {\rm d}x$

We'll operate in ${\mathbb C}(x, \psi = \exp \,ix)$ and evaluate

$$\int {{2i}\over{\psi - \psi^{-1}}} \,dx = \int 2i {{\psi}\over{\psi^2 - 1}} \,dx$$

Now we want a partial fractions expansion.  We could use a resultant,
or the Euclidean G.C.D. algorithm, but it's simpler to just note that
the denominator's a difference of squares and compute:

$${{c_1}\over{\psi-1}} + {{c_2}\over{\psi+1}} = {{\psi}\over{\psi^2-1}} $$

$${{c_1}(\psi+1)} + {{c_2}(\psi-1)} = \psi \qquad c_1 = c_2 = {1\over2} $$

giving us

$$\int \left[ {{i}\over{\psi-1}} + {{i}\over{\psi+1}} \right] dx$$

Now we have an integral in the form of equation
\eqref{exponential integration theorem - integrand}
with $\nu=2$, $n_1(\psi) = \psi -1$,
$n_2(\psi) = \psi + 1$,
$m_1=m_2=1$ and $c_{1,1} = c_{2,1} = i$.

$$D_{1} = \frac{c_{1,1}}{n_1'(\theta) - \frac{\lc n_1'(\theta)}{\lc n_1(\theta)} n_1(\theta)} = \frac{i}{i \psi - i (\psi-1)} = 1$$
$$D_{2} = \frac{c_{2,1}}{n_2'(\theta) - \frac{\lc n_2'(\theta)}{\lc n_2(\theta)} n_2(\theta)} = \frac{i}{i \psi - i (\psi+1)} = -1$$

so by Theorem \ref{exponential integration theorem}
the integral can be written:

$$\int \left[ {{i}\over{\psi-1}} + {{i}\over{\psi+1}} \right] dx
= \ln (\psi-1) - \ln(\psi+1) = \ln({{\psi-1}\over{\psi+1}})$$

$$ = \ln ({{e^{ix}-1}\over{e^{ix}+1}}) = \ln ({{e^{ix/2}-e^{-ix/2}}\over{e^{ix/2}+e^{-ix/2}}}) = \ln i {{\sin {x\over2}}\over{\cos {x\over2}}} = \ln \tan {x\over2} $$

where I dropped the $i$ at the end because, as a constant multiple
inside a logarithm, it disappears into the constant of integration,
and we conclude that

$$\int \csc x \,{\rm d}x = \ln \tan {x\over2} $$

\endexample

\vfil\eject

\example Compute $\int \tan x \, {\rm d}x$

We'll operate in ${\mathbb C}(x, \theta = \exp \,ix)$ and evaluate

$$-i \int \frac{\theta - \theta^{-1}}{\theta + \theta^{-1}} \,dx$$

The first step is write the integrand in partial fractions form:

$$\frac{\theta - \theta^{-1}}{\theta + \theta^{-1}} = \frac{\theta^2 - 1}{\theta^2 + 1}
= 1 - \frac{2}{\theta^2 + 1}
= 1 - \frac{2}{(\theta + i)(\theta - i)} $$

$$ = 1 + \frac{i}{\theta - i} - \frac{i}{\theta + i} $$

$$-i\, \frac{\theta - \theta^{-1}}{\theta + \theta^{-1}} = -i + \frac{1}{\theta - i} - \frac{1}{\theta + i} $$

This integrand is now in the form of equation
\eqref{exponential integration theorem - integrand} with
$n_1(\theta) = \theta -i$ and $n_2(\theta) = \theta + i$, $c_{1,1} = 1$,
$c_{2,1}=-1$, $a_0 = 1$ and $k=ix$, so plugging these values
into equation \eqref{eq: exponential Ds}, we obtain:


$$ D_1 = \frac{c_{1,1}}{n_1(\theta)' - \frac{\lc n_1'(\theta)}{\lc n_1(\theta)} n_1(\theta)} = \frac{1}{i \theta - i (\theta -i )} = -1$$
$$ D_2 = \frac{c_{2,1}}{n_2(\theta)' - \frac{\lc n_2'(\theta)}{\lc n_2(\theta)} n_2(\theta)} = \frac{-1}{i \theta - i (\theta +i )} = -1$$

Pluging this into equation \eqref{eq: exponential A0}, we obtain:

$$A_0' = a_0 - \sum_{i=1}^\nu D_i \frac{\lc n_i'(\theta)}{\lc n_i(\theta)}$$
$$A_0' = -i + 2i = i$$
$$A_0 = ix$$

so our integral is:

$$-i \int \frac{\theta - \theta^{-1}}{\theta + \theta^{-1}} \,dx
  = ix - \ln (\theta+i) - \ln(\theta-i)$$
$$  = ix - \ln \left[ (\theta+i)(\theta-i) \right]$$
$$  = ix - \ln \left[ \theta^2 + 1 \right]$$

We can convert this into a more familiar form by realizing 
that $ix = \ln \exp ix = \ln \theta$, so

$$  = \ln \theta - \ln \left[ \theta^2 + 1 \right]
= \ln \frac{\theta}{\theta^2 + 1}
= \ln \frac{1}{\theta^{-1} + \theta}$$

$$\int \tan x \, {\rm d}x = \ln \csc x$$

\endexample

\vfill\eject
\section{Risch Equations in ${\mathbb C}(x)$}

Risch equations in ${\mathbb C}(x)$ arise when our integrand exists in
a {\it simple} exponential extension of ${\mathbb C}(x)$,
i.e, an integrand formed as a rational function of $x$ and a
single exponential of a rational function of $x$.  Theorem
\ref{exponential integration theorem}
then produces Risch equations in the underlying field;
in this case, ${\mathbb C}(x)$.

Consider such a Risch equation:

\begin{equation}
\label{eq: C(x) Risch}
r' + S r = T \qquad S,T,r \in {\mathbb C}(x)
\end{equation}

Recall that in ${\mathbb C}[x]$, all irreducible factors have
the form $(x-\gamma)$, since ${\mathbb C}$ is algebraically
closed.  Futhermore, all irreducible factors in $r$'s
denominator increase in degree on differentiation,
since all of ${\mathbb C}[x]$'s factors are normal.
Therefore, the factors in $r$'s denominator must appear in
either $S$ or $T$'s denominator, because otherwise $r'$
would have a factor in its denominator that could not
cancel anything else in the equation.
Thus, we can easily identify
which factors can appear in $r$'s denominator, and we next
wish to calculate the multiplicities with which they appear.

Let's consider a single pole at
$\gamma$, expand $S$, $T$, and $r$ using partial fractions, and look
at the highest powers of $(x-\gamma)$ in the denominator:

$$r = \frac{a}{(x-\gamma)^j} + \cdots  \qquad  r' = \frac{-ja}{(x-\gamma)^{j+1}} + \cdots$$

$$S = \frac{b}{(x-\gamma)^k} + \cdots$$

$$T = \frac{c}{(x-\gamma)^l} + \cdots$$

Combining everything into the Risch equation \eqref{eq: C(x) Risch}, we find:

$$\frac{-ja}{(x-\gamma)^{j+1}} + \cdots + \frac{ba}{(x-\gamma)^{j+k}} + \cdots = \frac{c}{(x-\gamma)^l} + \cdots$$

We know $k$ (the pole's multiplicity in $S$'s denominator) and $l$ (the pole's
multiplicity in $T$'s denominator), and we wish to determine $j$, the
pole's multiplicity in $r$'s denominator.

We can classify the equation into three basic cases, based on the value of $k$:

\begin{enumerate}

\item $k=0$.  In this case, the $\frac{-ja}{(x-\gamma)^{j+1}}$ term dominates the left hand side,
and $j = l-1$ in order to match the right hand side.

\item $k=1$.  Here, the high order terms on the left are equal, so either $j=l-1$ in order to match
the right hand side, or $j=b$ and $j>l-1$ in order for the left hand terms to exactly cancel.

\item $k>1$.  Now the $\frac{ba}{(x-\gamma)^{j+k}}$ term dominates the left hand side, so $j=l-k$ in
order to match the right hand side.

\end{enumerate}

By checking all of $S$'s and $T$'s poles using this technique, we can
identify all the poles in $r$'s denominator and determine the
multiplicity with which they appear.  This determines $r$'s
denominator $d$ completely.

Having done so, we can replace $r$ with $p/d$, where $p,d \in {\mathbb C}[x]$:

$$\frac{p'd-pd'}{d^2} + S \frac{p}{d} = T$$

$$(p'd-pd') + S pd = T d^2$$

We still might have lingering denominators, which can be cleared by
multiplying through by $D$, the least common multiple of the
denominators of $Spd$ and $Td^2$:

$$ D (p'd-pd') + S D pd = T D d^2$$

$$(D d) p' + (S D d - D d')p = T D d^2$$

Setting $A=Dd$, $B=D(Sd - d')$ and $C=TDd^2$, we now have a polynomial Risch equation
that must be satisfied by the numerator $p$:

\begin{equation}
\label{eq: C[x] Risch}
A p' + B p = C \qquad A,B,C,p \in {\mathbb C}[x]
\end{equation}

Our next aim is to upper bound the degree of $p$, and there are again three cases.

First, the highest terms on the left can have higher degree than any term on
the right, and so must cancel against each other.  For this to occur,
$\deg A = \deg B + 1$ (since $\deg p$ drops by one on differentiation),
and we can determine $\deg p$ by looking at the leading
coefficients in $A$ and $B$:

$$A = a_j x^j + \cdots \qquad B = b_{j-1} x^{j-1} + \cdots \qquad p = p_k x^k \cdots$$

$$A p' + B p = (k a_j p_k + b_{j-1} p_k) x^{j+k-1} \cdots$$

In order for this coefficient to be zero, $k=-b_{j-1}/a_j$.
So, if these conditions are met:

$$\deg A = \deg B + 1 \qquad k=-\frac{b_{j-1}}{a_j} = -\frac{\lc B}{\lc A}$$

then $p$ may exist as a $k^{\rm th}$ degree polynomial.

Otherwise, the leading terms of $A p' + B p$ do not cancel out,
so they must match the leading term of $C$.  This can only
occur if

$$\deg p = \deg C - \max(\deg A - 1, \deg B)$$

The final case we need to consider is when $p$ is a constant, which
would solve the Risch equation if and only if $C$ was a constant
multiple of $B$, irregardless of $A$.

Summarizing, equation \eqref{eq: C[x] Risch} can be solved only if one
of these three conditions is met:

\begin{enumerate}
\item $\deg A = \deg B + 1$ and $\deg p =-\frac{\lc B}{\lc A} $
\item $\deg p = \deg C - \max(\deg A - 1, \deg B)$
\item $p$ is a constant and $pB = C$
\end{enumerate}

They are not mutually exclusive.  In particular, if both of the first
two cases can be met, then the larger of the two values for $\deg p$
should be used.

Having determined the degree of $p$, we can now determine its
coefficients by hypothesizing $p$ as a polynomial of the calculated
degree and plugging it into equation \eqref{eq: C[x] Risch}.

\vfill\eject

\example
\label{exp e^{-x^2}}
Prove that $\int e^{-x^2}\, {\rm d}x$ has no elementary form

We'll use ${\mathbb C}(x, \psi = \exp\, -x^2)$, so $\psi' = -2x$ and
study

$$\int \psi \, {\rm d}x$$

We know from Theorem \ref{exponential integration theorem} that our
solution, if it exists, must have the form $A_1\psi$, where $A_1 \in
{\mathbb C}(x)$, and $A_1$ must satisfy equation \eqref{eq: exponential An}:

$$A_1' - 2x A_1 = 1$$

This is already a polynomial Risch equation, and $A_1'$ has only a
constant coefficient, so $A_1$ can not have a non-trivial denominator.
Futhermore, identifying $A$ as $1$, $B$ as $-2x$, and $C$ as $1$, we
see that $\deg A = 0$ and $\deg B = 1$.  Since $\deg A \ne \deg B + 1$
(case 1), the leading terms on the left hand side can not cancel, so
they must match the leading term on the right.  We compute:

$$\deg C - \max(\deg A - 1, \deg B) = 0 - 1 = -1$$

so that doesn't work (case 2).  Futhermore, $C$ is not a constant
multiple of $B$, so a constant can't solve our equation (case 3).

We conclude that no solution to this Risch equation exists in ${\mathbb C}(x)$,
so the integral can not be expressed in elementary form.

\endexample


\example Prove that $\int \frac{\sin x}{x} \, {\rm d}x$ has no elementary form

As we often do with trigonometric integrals, we'll operate in
${\mathbb C}(x, \psi = \exp \,ix)$, use Euler's relationship
$e^{ix}=i\sin x + \cos x$, and evaluate

$$\int \frac{\psi - \psi^{-1}}{2ix} \,dx$$

Let's begin by writing the integrand in the form of a rational
function in ${\mathbb C}(x)(\psi)$, i.e, a ratio
of $\psi$-polynomials, with coefficients in ${\mathbb C}(x)$:

$$\frac{1}{2i} \int \left[ \frac{1}{x}\psi - \frac{1}{x}\frac{1}{\psi} \right]\,dx$$

\begin{comment}
% This text doesn't belong here
We want to split the denominator into its normal and special
components, by factoring it into irreducible polynomials and
classifying each one as normal or special.  In this case, the
factoriziation is trivial, and we know from theorem \ref{basic
exponential properties} that $\psi$ is special.

Can we have any logarithms in our integral?  Let's see.
Any logarithm of a rational function can be factored and
split into separate logarithms using basic properties
of a logarithms:

$$\ln ab = \ln a + \ln b \qquad\qquad \ln\frac{a}{b} = \ln a - \ln b$$

So, we need only consider logarithms of irreducible polynomials.

Theorem \ref{basic exponential properties} also tells us that we can
have no normal polynomials in denominator of our integral,
\end{comment}


Applying theorem \ref{exponential integration theorem}, we see that
the integral must have the form $A_1 \psi + A_{-1} \frac{1}{\psi}$
with $A_1, A_{-1} \in {\mathbb C}(x)$ and must satisfy
equations \eqref{eq: exponential An}:

$$A_1' + i A_1 = \frac{1}{x} \qquad A_{-1}' - i A_{-1} = - \frac{1}{x}$$

In both cases, we've got an equation of the form \eqref{eq: C(x) Risch}
with a single pole in the denominator of $T$, so $k=0$, $l=1$,
and $j=l-1=0$, so there are no poles in the denominator of our solution.
However, there is then no way to produce the denominator on the
right, so the Risch equation has no solution in ${\mathbb C}(x)$.


Thus, the integral can not be expressed in elementary form.

\endexample

\vfil\eject

Partial fractions terms involving normal polynomials are handled the
same way as, well, normal polynomials.  Terms with simple denominators
give rise to logarithms in the solution, while terms with higher
powered denominators give rise to rational functions in the solution.

One unusual feature of exponential extensions is that the numerator of
a derivative will have the same degree as the denominator, so a long
division step is needed to make the fraction proper, and this will
produce a constant that will modify the integrand.  For this reason,
it's best to handle the denominator's normal factors first,



\begin{comment}

\vfil\eject

\example Compute $\int {{4^x-1}\over{2^x+1}} {\rm d}x$
\label{integrate 4^x-1/2^x+1}

We'll use the field ${\mathbb C}(x,\Psi = \exp(x \ln 2))$; $\Psi' =
(\ln 2)\Psi$ and the representation (see Example
\ref{represent 4^x+1/2^x+1}):

$$ \frac{\Psi^2-1}{\Psi+1} = \Psi-1$$

So we need to find a solution of the form $a\Psi + \bar{b}$ ($\bar{b}$
can include additional logarithmic elements) that satisfy the Risch
equations:

$$a'\Psi + a\Psi' = a'\Psi + a(\ln 2)\Psi = \Psi \qquad a' + a(\ln 2) = 1$$
$$\bar{b}' = -1$$

Both equations have fairly obvious solutions:

$$a = \frac{1}{\ln 2} \qquad \bar{b}=-x$$

So our solution is

$$\int {{4^x+1}\over{2^x+1}} {\rm d}x = \frac{1}{\ln 2}\Psi - x =
\frac{1}{\ln 2}2^x - x$$

\endexample

\end{comment}

\vfil\eject

\example Compute $\int {{4^x+1}\over{2^x+1}} {\rm d}x$
\label{integrate 4^x+1/2^x+1}

We'll use the field ${\mathbb C}(x,\theta = \exp(x \ln 2))$; $\theta' =
(\ln 2)\theta$ and the representation (see Example
\ref{represent 4^x+1/2^x+1}):

$$ \frac{\theta^2+1}{\theta+1} = \theta-1+\frac{2}{\theta+1}$$

This integrand has the form of equation
\eqref{exponential integration theorem - integrand}
with $a_1=1$, $a_0=-1$, $n_1(\theta)=\theta+1$,
$n_1'(\theta) = (\ln 2)\theta$ and $c_{1,1}=2$.

We'll start with equation
\eqref{eq: exponential Ds}:

$$ D_1 = \frac{c_{1,1}}{n_1(\theta)' - \frac{\lc n_1'(\theta)}{\lc n_1(\theta)} n_1(\theta)} = \frac{2}{(\ln 2) \theta - \frac{\ln 2}{1} (\theta +1 )} = -\frac{2}{\ln 2}$$

Now, equation \eqref{eq: exponential An} yields:

$$A_1' + (\ln 2) A_1 = 1 \qquad\Longrightarrow\qquad A_1 = \frac{1}{\ln 2}$$

and equation \eqref{eq: exponential A0} yields:

$$A_0' = a_0 - D_1 \frac{\lc n_i'(\theta)}{\lc n_i(\theta)} = -1 + \frac{2}{\ln 2} \ln 2 = 1$$

$$A_0 = x$$

Plugging everything into equation \eqref{exponential integration theorem - integral},
then substituting $2^x$ for $\theta$,
we obtain our solution:

$$\int {{4^x+1}\over{2^x+1}} {\rm d}x = \frac{1}{\ln 2}\theta + x  - \frac{2}{\ln 2}\left[\ln(\theta+1)\right] =
\frac{2^x}{\ln 2} + x - \frac{2}{\ln 2}\ln(2^x+1) $$

\endexample

\vfill\eject

\example
Redo Example \ref{hard log-exp integral} using the exponential theory.

$$\int{{x\{(x^2e^{2x^2}-\ln^2(x+1))^2+2xe^{3x^2}(x-(2x^3+2x^2+x+1)\ln(x+1))\}}\over{(x+1)(\ln^2(x+1) - x^2e^{2x^2})^2}} dx$$

We proceed as before, putting the integral into Liouvillian form
and dividing out $\frac{x}{x+1}$ to obtain a proper fraction:

\begin{sageblock}
F.<x,theta> = FractionField(ZZ['x', 'theta']);
Ring.<psi> = F['psi']

D = Derivation(Ring, {x: 1, theta: 1/(x+1), psi: 2*x*psi})

num = Ring(lintegrand.numerator(False))
den = Ring(lintegrand.denominator(False))

(a,N) = num.quo_rem(den)
\end{sageblock}

This time, we'll operate in ${\mathbb C}(x,\theta = \ln (x+1),\psi = \exp x^2)$, treating
this as an exponential extension of ${\mathbb C}(x,\theta)$.  We'll begin again by
computing a partial fractions expansion, this time with respect to $\psi$:

\begin{sageblock}
n = [f[0] for f in factor(den)]

c = partfrac(N, den);
displayarray(c);
\end{sageblock}

Now Theorem \ref{exponential integration theorem} tells us that

\begin{sageblock}
R = {};
R[0,1] = c[n[0],2]
\end{sageblock}

$$C_{0,1}(\psi) = - \frac{R_{0,1}(\psi)}{n_0'(\psi)} \mod n_0(\psi)$$

This time, we do need to perform a modulo reduction, but as modulo reductions go, it's
trivial.  We construct a quotient ring, map our operands into it, and perform
the division there.

\begin{sageblock}
F2 = Ring.quo(n[0]);
C[0,1] = - F2(R[0,1]) / F2(D(n[0]))
\end{sageblock}

Now we wish to compute $Q_{0,1}(\psi)$.  There is no modulo reduction in
this division, and it should always be exact.  We {\tt lift} the result
of the modulo reduction back into its parent ring, and use {\tt //} to
perform exact division (as opposed to working in a fraction field).

$$Q_{0,1}(\psi) = - \frac{R_{0,1}(\theta) + C_{0,1}(\theta) n_0'(\theta)}{n_0(\theta)}$$

\begin{sageblock}
Q = {};
Q[0,1] = - (R[0,1] + C[0,1].lift() * D(n[0])) // n[0]
\end{sageblock}

Having computed $C_{0,1}$ and $Q_{0,1}$, we are now able to compute $D_0$:

$$ D_0 = \frac{c_{0,1} - C_{0,1}'(\psi) - Q_{0,1}(\psi)}{n_0'(\psi) - \frac{\lc n_0'(\psi)}{\lc n_0(\psi)} n_0(\psi)}$$

\begin{sageblock}
myD = {};
myD[0] = (c[n[0],1] - D(C[0,1].lift()) - Q[0,1]) \
  / (D(n[0])-D(n[0]).lc()/n[0].lc()*n[0])
\end{sageblock}

% XXX I'd like to drop the semicolor in the \maximac element.

%A similar calculation for $n_1(\psi) = \maximac{n[2];}$ yields
A similar calculation for $n_1(\psi) = \sage{n[1]}$ yields yields

\begin{sageblock}
R[1,1] = c[n[1],2]
F2.<zbar> = Ring.quo(n[1]);
C[1,1] = - F2(R[1,1]) / F2(D(n[1]))
Q[1,1] = - (R[1,1] + C[1,1].lift() * D(n[1])) // n[1]
myD[1] = (c[n[1],1] - D(C[1,1].lift()) - Q[1,1]) \
  / (D(n[1])-D(n[1]).lc()/n[1].lc()*n[1])
\end{sageblock}

In an exponential extension, our $D$ coefficients can affect our $A_0$ term...

$$A_0' = a_0 - \sum_{i=1}^\nu D_i \,\frac{\lc n_1'(\psi)}{\lc n_1(\psi)} $$

\begin{sageblock}
a = a - sum([myD[i]*D(n[i]).lc()/n[i].lc() for i in range(2)])
A = integrate(a,x)
\end{sageblock}

We end up with
the same result that we obtained from the logarithmic theory:

\begin{sagespacedblock}
lans = A + sum([C[i,1].lift()/n[i] for i in range(2)]) \
  + sum([2 * myD[i] * log(n[i]) for i in range(2)]).simplify_log()/2
ans = lans.subs({theta : log(x+1), psi : exp(x^2)})
bool(diff(ans,x) == integrand)
\end{sagespacedblock}

\endexample

\vfill\eject
\section{Risch Equations over Normal Polynomials}

Now let's expand our study to include Risch equations in more
complicated differential fields, starting with normal polynomials,
which will allow us to handle logarithmic extensions.

Consider again such a Risch equation, this time in a simple
transcendental extension $K(\theta)$ of an arbitrary differential
field $K$:

$$r' + S r = T \qquad S,T,r \in K(\theta)$$

Once again, we can perform a partial fractions expansion on $S$, $T$,
and $r$, except that this time our irreducible polynomials are more
complicated that $(x-\gamma)$.  Consider one such normal irreducible
polynomial $n(\theta)$:

$$S = \frac{b(\theta)}{n(\theta)^k} + \cdots
\qquad T = \frac{c(\theta)}{n(\theta)^l} + \cdots$$

$$r = \frac{a(\theta)}{n(\theta)^j} + \cdots  \qquad
r' = \frac{a'(\theta)n(\theta)-ja(\theta)n'(\theta)}{n(\theta)^{j+1}} + \cdots = \frac{-ja(\theta)n'(\theta)}{n(\theta)^{j+1}} + \cdots$$

Plugging this all into the Risch equation, we obtain:

$$\frac{-ja(\theta)n'(\theta)}{n(\theta)^{j+1}} + \cdots + \frac{a(\theta) b(\theta)}{n(\theta)^{j+k}} + \cdots = \frac{c(\theta)}{n(\theta)^l} + \cdots$$

Both of the numerators on the left hand side could have $\theta$-degree greater than $\deg_\theta n(\theta)$,
so we divide them by $n(\theta)$:

% Dividing the numerator of $r'$ by $n(\theta)$, we obtain:

% $$-ja(\theta)n'(\theta) = Q(\theta) n(\theta) + R_1(\theta)$$

$$R_1(\theta) = -ja(\theta)n'(\theta) \mod n(\theta)$$
$$R_2(\theta) = a(\theta)b(\theta) \mod n(\theta)$$

% $$r = \frac{a(\theta)}{n(\theta)^j} + \cdots  \qquad  r' = \frac{R_1(\theta)}{n(\theta)^{j+1}} + \cdots$$

% Plugging this all into the Risch equation, we obtain:

$$\frac{R_1(\theta)}{n(\theta)^{j+1}} + \frac{R_2(\theta)}{n(\theta)^{j+k}} = \frac{c(\theta)}{n(\theta)^l}$$

% $$R_2(\theta) = a(\theta)b(\theta) \mod n(\theta)$$

Since $n(\theta)$ is irreducible, $K/(n_i)$ is a field, so it has no zero divisors, and
neither $R_1(\theta)$ and $R_2(\theta)$ are zero.

Our three cases are as before, except that when $k=1$, our cancellation condition becomes:

$$R_1(\theta) = -R_2(\theta) \mod n(\theta)$$

$$ja(\theta)n'(\theta) = a(\theta)b(\theta) \mod n(\theta)$$

Again, division is possible in a field, so

$$j = \frac{b(\theta)}{n'(\theta)} \mod n(\theta)$$

Our three cases become:

\begin{enumerate}

\item $k=0$ and $j = l-1$.

\item $k=1$ and either $j=l-1$ or $j = \frac{b(\theta)}{n'(\theta)} \mod n(\theta)$.

\item $k>1$ and $j=l-k$.

\end{enumerate}

Once we have determined the factors and multiplicities in the denominator,
then we can proceed as before, clearing out the denominator and obtaining
a polynomial equation of the form:

\begin{equation}
\label{eq: K[theta] normal Risch}
A p' + B p = C \qquad A,B,C,p \in K[\theta]
\end{equation}

In addition to the three cases that we considered for ${\mathbb C}[x]$,
there is a fourth case that must be considered.  $p$ can be
zeroth order in $\theta$, yet not be a constant.  So our
cases become:

\begin{enumerate}
\item $\deg_\theta A = \deg_\theta B + 1$ and $\deg_\theta p =-\frac{\lc B}{\lc A} $
\item $\deg_\theta p = \deg_\theta C - \max(\deg_\theta A - 1, \deg_\theta B)$
\item $\deg_\theta p = 0$
\item $p$ is a constant and $pB = C$
\end{enumerate}

\vfill\eject

\example Determine if $\int x^x dx$ has an elementary form.

To handle this integral, we'll rewrite it as $\int e^{x \ln x} dx$
and operate in the field ${\mathbb C}(x, \theta, \psi)$, where
$\theta = \ln x$ and $\psi = \exp x\theta$.  So, we're
trying to compute

$$\int \psi\, dx$$

Applying theorem \ref{exponential integration theorem}, we
obtain the following Risch equation in
${\mathbb C}(x, \theta)$:

$$A_1' + k' A_1 = 1$$

\begin{equation}
\label{x^x Risch equation}
A_1' + (\theta + 1) A_1 = 1
\end{equation}

$$A=1 \qquad B=\theta +1 \qquad C=1$$

Since $\deg A = 0$ and $\deg B=1$, $\deg A \ne \deg B + 1$,
so we can't have cancellation on the left hand side.
This means that

$$\deg A_1 = \deg C - \max(\deg A - 1, \deg B) = 0 - \max(-1, 1) = -1$$

which is impossible.

If $\deg_\theta A_1$ is zero,
then $A_1 \in {\mathbb C}(x)$ and equation
\eqref{x^x Risch equation}
splits into two Risch equations in ${\mathbb C}(x)$,
one for first degree
terms in $\theta$ and one for zeroth degree
terms in $\theta$:

$$A_1 = 0$$
$$A_1' + A_1 = 1 \qquad\Longrightarrow\qquad A_1 = -1$$

These equations have no simultaneous solution.

We conclude that equation \eqref{x^x Risch equation} has no solution
in ${\mathbb C}(x, \theta)$, and that the original integral
is not elementary.

\endexample

\vfill\eject
\section{Normal Risch Equations in Sage}

To facilitate use of Sage, I've written a Risch equation
solver in Sage.

First, we want a partial fractions expansion that's a little bit
different from the standard function {\tt partfrac}.  If {\it expr}
isn't a fraction, or if its denominator doesn't involve the variable
{\it var}, we want an empty list returned, otherwise return a list of
the fractions in the expansion.  We just want the highest-powered
term in the expansion.

\begin{sagecommon}
def partfrac1(num, den):
   b = {}
   if den != 1:
     factorization = factor(den)
     for f in factorization:
       (t,s) = diophantine(num, f[0]^f[1], den//(f[0]^f[1]))
       (q,r) = s.quo_rem(f[0])
       b[f[0]] = [r, f[1]]
   return(b)
\end{sagecommon}

Next, given a Risch equation in the form

$$r' + S r = T$$

{\tt normal_risch_factors} returns a list of sublists, with one
sublist for each irreducible factor in $S$ or $T$'s denominator.  Each
sublist contains the factor along with a pair of lists, one for $S$
and one for $T$, containing the highest power in that
variable's partial fractions expansion, along with the corresponding
numerator, in the following format:

\begin{center}
\begin{verbatim}
[factor, [S-numerator, S-power], [T-numerator, T-power]]
\end{verbatim}
\end{center}

\begin{sagecommon}
def normal_risch_factors(S, T):
   result = {}
   Sb = partfrac1(S.numerator(), S.denominator())
   Tb = partfrac1(T.numerator(), T.denominator())
   for f in set(Sb.keys()).union(Tb.keys()):
      result[f] = [Sb.get(f, [0,1]), Tb.get(f, [0,1])]
   return result
\end{sagecommon}

{\tt normal_risch_denominator} uses {\tt normal_risch_factors}
to compute the solutions's denominator.

\begin{sagecommon}
def is_integer(P):
   try:
      int(P)
      return True
   except (TypeError, ValueError):
      return False

def normal_risch_denominator1(L, D):
   (f, [[Snum, k], [Tnum, l]]) = L
   if k == 0:
      return f^max(0,l-1)
   elif k == 1:
      R = f.parent().quo(f)
      j = R(Snum)/R(D(f))
      if is_integer(j):
         return f^max(l-1, j, 0)
      else:
         return f^max(l-1, 0)
   else:
      return f^max(0,l-k)

def normal_risch_denominator(S, T, D):
  return prod(map(lambda L: normal_risch_denominator1(L, D), normal_risch_factors(S,T).items()))
\end{sagecommon}

The next function, {\tt normal_risch_polynomial}, given $S$, $T$, and
the denominator computed by {\tt normal_risch_denominator},
returns the components of the polynomial equation
satisfied by the solution's numerator:

$$A n' + B n = C$$

in the form {\tt [A, B, C]}.

\begin{sagecommon}
def normal_risch_polynomial(S, T, D1, D):
  D2 = (S*D1).denominator() * (T*D1).denominator()
  # XXX check to make sure that denominator is 1
  return [D1*D2, S*D1*D2 - D(D1)*D2, (T*D1^2*D2).numerator()]
\end{sagecommon}

Next, given $A$, $B$, and $C$, we wish to compute the
maximum degree of the numerator, or {\tt None} if we can
determine at this point that there is no solution.

\begin{sagecommon}
def is_constant(P, D):
   return (D(P) == 0)

def normal_risch_degree(A, B, C, D):

   # XXX What if B is zero?

   if C != 0:
      k = C.degree() - max(A.degree() - 1, B.degree())
   else:
      k = -1

   if is_constant(C/B, D):
      k = max(k,0)

   if A.degree() == B.degree() + 1:
      p = - B.lc() / A.lc()
      if is_integer(p):
         k = max(k,p)

   return k
\end{sagecommon}

Finally, we combine all these pieces together into a function that
either returns a solution to a normal Risch equation, or {\tt None}
if no such solution exists.

\begin{sagecommon}
def normal_risch_equation(S, T, D):
  D1 = normal_risch_denominator(S, T, D)
  [A, B, C] = normal_risch_polynomial(S, T, D1, D)

  if is_constant(C/B, D):
     return C/B/D1
  elif normal_risch_degree(A,B,C,D) == -1:
     return None
  else:
     raise NotImplementedError
\end{sagecommon}

Let's demonstrate the use of this code by using it to solve the Risch
equations that we've already seen in this chapter's examples so far.

\begin{sageblock}
R.<x> = QQbar[]
I = R(sqrt(R(-1)))
D = Derivation(R, {x: 1})
normal_risch_equation(I, 1/(2*I), D)
normal_risch_equation(-2*x, R(1), D)
normal_risch_equation(I, 1/x, D)

C2.<log2> = QQbar[]
C2._latex_names[0] = '{\ln 2}'
R2.<x> = C2[]
D = Derivation(R2, {x: 1, log2: 0})
normal_risch_equation(R2(log2), R2(1), D)

R2.<theta> = R[]
D = Derivation(R2, {x: 1, theta: 1/x})
normal_risch_equation(theta+1, R2(1), theta)
\end{sageblock}

\vfill\eject
\section{Risch Equations over Special Polynomials}

Finally, let's consider Risch equations over fields
with special polynomials, i.e, exponential extensions
with $\theta = \exp k$ and $\theta' = k' \theta$.

$$r' + S r = T \qquad S,T,r \in K(\theta)$$

First, what happens when our partial
fractions decomposition yields special polynomials
in the denominators of $S$ or $T$?

$$S = \frac{b}{\theta^k} + \cdots \qquad T = \frac{c}{\theta^l} + \cdots \qquad b,c \in K$$


%% $$r = \frac{a(\theta)}{n(\theta)^j} + \cdots  \qquad  r' = \frac{-ja(\theta)n'(\theta) + a'(\theta)n(\theta)}{n(\theta)^{j+1}} + \cdots$$

%% $$r = \frac{a(\theta)}{n(\theta)^j} + \cdots  \qquad  r' = \frac{-ja(\theta)\frac{n'(\theta)}{n(\theta)} + a'(\theta)}{n(\theta)^{j}} + \cdots$$

$$r = \frac{a}{\theta^j} + \cdots  \qquad  r' = \frac{-j k' a + a'}{\theta^{j}} + \cdots \qquad a \in K$$

First, we should consider if the leading $r'$ term actually exists.
Could the numerator actually be zero?  If so, then $j k' a = a'$,
but this could only happen if $a$ were a constant
multiple of $\theta^j$ (PROVE THIS), which contradicts the
transcendance of $\theta$ over $K$.

Our Risch equation becomes:

$$\frac{-j k' a + a'}{\theta^{j}} + \cdots + \frac{a b }{\theta^{k+j}} + \cdots
= \frac{c}{\theta^l} + \cdots$$

There are two cases:

\begin{enumerate}
\item $k=0$ and either $j=l$ or
$j = \frac{a' + a b}{a k'}$
%% (assuming that this fraction is an integer).
\item $k>0$ and $j=l-k$.
\end{enumerate}

Now we have computed $j$, the multiplicity of the special factor
$\theta$ in the
denominator, and our normal theory from the previous section gives us
the denominator multiplicity of our normal factors, so
we've computed $d$, the denominator of $r$, and
thus can replace $r$ with $p/d$, which will
yield a polynomial Risch equation.

There are additional issues that arises with special polynomials when
solving a polynomial Risch equation:

\begin{equation}
\label{eq: special polynomial Risch}
A r' + B r = C \qquad A,B,C \in K[\theta] \quad r \in K(\theta)
\end{equation}

If $K[\theta]$ has only normal polynomials, then this equation can be
solved as described before, since $r$ must be a polynomial.
In the special case, however, $r$ could have a special denominator.
Expanding as before...

$$r = \frac{a}{\theta^j} + \cdots  \qquad  r' = \frac{-j k' a + a'}{\theta^{j}} + \cdots$$

If $A$ and $B$ have no $\theta$ factors, then their zeroth order coefficients will produce $j$-th order fractions:

$$ A(0) \frac{-j k' a + a'}{\theta^{j}} + \cdots
+ B(0) \frac{a}{\theta^j} + \cdots  = C$$

Since $C$ is a polynomial, the fractions on the left must cancel, and we obtain:

$$\left[ -j a k' + a' \right] A(0) + a B(0) = 0$$

%% $$j = \frac{a(\theta) B(0) - a'(\theta) A(0)}{a(\theta)k'}$$

%%$$\left[ jk' + \frac{a'(\theta)}{a(\theta) } \right] = \frac{B(0)}{A(0)}$$
$$ jk' - \frac{a'}{a }  = \frac{B(0)}{A(0)}$$

Integrating, we obtain:

\begin{equation}
\label{special risch equation - denominator bound}
jk - \ln a = \int \frac{B(0)}{A(0)} dx
\end{equation}

We don't know $a$, but $A$, $B$, and $k$ are all known, so solving
this equation amounts to an integration step that must result in a
constant multiple of $k$ plus a possible logarithm.

This completes our determination of the denominator of $r$, and we
are now reduced to a polynomial equation:

\begin{equation}
\label{special risch polynomial equation}
A p' + B p = C \qquad A,B,C,p \in K[\theta]
\end{equation}

$$p = p_n \theta^n + \cdots \qquad p' = (p_n' + n p_n k') \theta^n + \cdots$$

So the leading term on the left hand side is:

$$\lc A (p_n' + n p_n k') + \lc B p_n = 0$$

$$n k' + \frac{p_n'}{p_n} = - \frac{\lc B}{\lc A}$$

This equation has the same form as \ref{special risch equation - denominator bound}, so again, we integrate:

\begin{equation}
\label{special risch equation - numerator bound}
n k + \ln p_n = - \int \frac{\lc B}{\lc A} dx
\end{equation}

If this integral has this desired form, then cancellation
is possible between the terms on the left hand side of
\ref{special risch polynomial equation}, and
$n$ is the $\theta$-degree
of the solution polynomial.

Otherwise, there is no cancellation and 
$\deg_\theta p = \deg_\theta C - \max(\deg_\theta A, \deg_\theta B)$

This degree can be negative, so long as it is no lower than
the lower degree bound determined earlier.

\vfill\eject

\example (\cite{bronstein book} examples 6.2.1, 6.3.3, 6.4.2) Integrate
$$\int \frac{e^x - x^2 + 2x}{(e^x + x)^2 x^2}e^{(x^2-1)/x+1/(e^x+x)} dx$$

We'll use the differential field ${\mathbb C}(x, \theta, \psi)$ where
$\theta = \exp x$ and $\psi = \exp\left( \frac{x^2-1}{x}+\frac{1}{\theta+x}\right)$.

\begin{sageblock}
# First, we switch back to using the Symbolic Ring,
# instead of the ring variables from the last example.

x = var('x');
theta = var('theta');
psi = var('psi');

integrand =                         \
   (exp(x) - x^2 + 2*x)             \
      / ((exp(x) + x)^2 * x^2)      \
   * exp((x^2-1)/x + 1/(exp(x)+x))

exponent = (x^2-1)/x + 1/(theta+x)
lintegrand = integrand.subs(
   {exp(x)        : theta,
    exp(exponent) : psi})

# Now create a proper ring and convert to using its variables.

F.<x,theta> = FractionField(ZZ['x', 'theta']);
R.<psi> = F[]

D1 = Derivation(R, {x: 1, theta: theta})
D = Derivation(R, {x: 1, theta: theta, psi: D1(R(exponent))*psi})
\end{sageblock}

The integrand has the form $a_1 \psi$, where
$a_1 \in {\mathbb C}(x, \theta)$, so we're ready to apply
Theorem \ref{exponential integration theorem}.
Equation \eqref{eq: exponential An} gives:

\begin{sageblock}
a1 = lintegrand/psi
A1f = function('A1', nargs=1);
A1 = A1f(x)
eq = diff(A1,x) + D(psi)/psi * A1 - a1
\end{sageblock}

\begin{comment}
(theta+x)^2*%;
/* eq: ratexpand(%); */
/* facsum(eq*x^2,rr); */

deepmap(func, expr, level) :=
   if is(level > 0) then map(lambda([u], deepmap(func, u, level-1)), expr)
                else func(expr);

deepmap(factor, eq, 2);
\end{comment}

This is already in the form required by equation ?:

$$r' + S r = T \qquad S,T,r \in K(\theta)$$

with $S$ and $T$ expanded in partial fractions.  None of the
denominator factors are special (only factors of the form $\theta^n$
are special), and both $(\theta+x)$ and $x$ are normal polynomials
with $k=2$ (the multiplicity in $S$'s denominator) and $l=2$
(the multiplicity in $T$'s denominator).  Case 3 in ? tells us
that $j=l-k=0$, so neither of these factors can appear
in the denominator of $r$.

Next we can move on to equation \ref{eq: special polynomial Risch}:

\begin{equation*}
A r' + B r = C \qquad A,B,C \in K[\theta] \quad r \in K(\theta)
\end{equation*}

Let's use {\tt numerator()} to collapse the entire equation into a
single fraction and discard the denominator, and
then extract the coefficients of $A_1$ and $A_1'$.

\begin{sageblock}
[BC, _], [A, _] = \
   eq.numerator().coefficients(diff(A1,x));
[C, _], [B, _] = \
   BC.numerator().coefficients(A1);
A
B
C
\end{sageblock}

Now we want to integrate $A(0)/B(0)$, to determine the highest power
of $\theta$ that can appear in the denominator:

\begin{sageblock}
(A/B).subs(theta=0)
\end{sageblock}

Since $\theta=e^x$, $k=x$, this solves equation \ref{special risch
equation - denominator bound} with $j=1$ and $a$ constant, which tells
us that $\theta$ can appear in $r$'s denominator with multiplicity
one.

What about the polynomial degree?

\begin{sageblock}
R2 = ZZ['x']['theta']
R2(B).lc() / R2(A).lc()
integrate(R2(B).lc() / R2(A).lc(), x)
\end{sageblock}

This does not have the desired form of \ref{special risch equation - numerator bound},
specifically it is not an integer multiple of $x$ plus a logarithm, so we lack cancellation.
This means that $A_1$'s $\theta$-degree is upper bounded by
$\deg_\theta C - \max(\deg_\theta A, \deg_\theta B) = -1$.
Since the lower bound is also $-1$, this
gives us the following form for $A_1$:

$$A_1 = A_{1,-1} \theta^{-1} \qquad A_{1,-1} \in {\mathbb C}(x)$$

Sage doesn't know how {\tt theta} differentiates\footnote{Maxima is
somewhat better in this regard.  It's {\tt gradef} command lets the
user declare how variables differentiate.}, so I expanded
it out by hand:

\begin{sageblock}
A1m1f = function('A1m1', latex_name='A_{1,-1}', nargs=1);
A1m1 = A1m1f(x);
eq2 = eq.subs({A1 : A1m1/theta,
   diff(A1,x) : (diff(A1m1,x)*theta - A1m1*D(theta))/theta^2})
eq2.numerator()
\end{sageblock}

This can also be done with more sophisticated tools.  We create a
differential ring involving $A_1$, $A_{1,-1}$ and $\theta$, with $x$
as its sole derivation.  An elimination ordering is used (the
default), with $A_1$ appearing earlier in the list than $A_{1,-1}$,
thus eliminating $A_1$ in favor of $A_{1,-1}$.  Then we construct a
differential ideal showing how $\theta$ differentiates and how $A_1$
is related to $A_{1,-1}$.  Finally, we reduce our equation modulo the
single differential chain in the differential ideal, producing a
normal form with the desired result.\footnote{This is also somewhat
painful with Sage, requiring us to convert $\theta$ into a
``function'' so that we can take its derivative.}

\begin{sageblock}
function('thetaf', latex_name='\\theta', nargs=1);
eq2a = eq.subs({theta: thetaf(x)});

from sage.calculus.DifferentialAlgebra import DifferentialRing
DR = DifferentialRing(derivations = [x],
                      blocks = [A1f,A1m1f,thetaf])

rels = [diff(thetaf(x),x) == thetaf(x),
        A1 == A1m1/thetaf(x)]
ideal = DR.RosenfeldGroebner(rels)

ideal[0].normal_form(eq2a)
ideal[0].normal_form(eq2a).simplify()
eq2b = ideal[0].normal_form(eq2a).numerator()
\end{sageblock}

% Returning to equation \eqref{eq: exponential An}, I'll collect all the
% terms over a common denominator using {\tt ratsimp}, then pull out the
% numerator, which is the expression we're setting equal to zero.
% A call to Maxima {\tt ev} function subsitutes in the value for
% $A_1$ that I just set, and specifying the {\tt diff} flag causes
% the derivatives to be expanded.

$A_{1,-1}$ is a rational functions in
${\mathbb C}(x)$.  In particular, it does not involve $\theta$, so
each power of $\theta$ in this equation must be zero.
Let's extract the leading $\theta$ coefficient and set it equal to zero.

\begin{sageblock}
eq2.numerator().coefficient(theta, 2)
eq2b.coefficient(thetaf(x)^2)
\end{sageblock}

This Risch equation has an obvious solution.  Now we're solving
in ${\mathbb C}(x)$, so if it were difficult, we could use the theory
of the previous section:

\begin{sageblock}
R2.<x> = QQbar[];
D = Derivation(R2, {x: 1});
normal_risch_equation(1/x^2, 1/x^2, D)
\end{sageblock}

Having solved for $A_{1,-1}$, we've now solved for $A_1$:

\begin{sageblock}
A1 = R(1/theta)
\end{sageblock}

Since our integrand was of the form $a_1 \psi$, our integral is of the
form $A_1 \psi$, so we've completed our calculation.  Is it correct?

\begin{sagecode}

# BUG FIX - the polynomial subs() routine doesn't call subs
# recursively, so only the top level polynomial var gets
# replaced.  The difference is the nested call to subs()

def bwbsubs(self, *x, **kwds):
    if len(x) == 1 and isinstance(x[0], dict):
        g = self.parent().gen()
        if g in x[0]:
            return self(x[0][g]).subs(x[0])
        elif len(x[0]) > 0:
            raise TypeError("keys do not match self's parent")
        return self
    return self(*x, **kwds)

# Python insanity!  This changes the class's method to use my patched
# version.

type(psi).subs = bwbsubs;

\end{sagecode}

\begin{sageblock}
lans = psi/theta
ans = lans.subs({psi : exp(exponent), theta : exp(x)})
bool(diff(ans,x) == integrand)
\end{sageblock}


\endexample

\begin{comment}
\vfill\eject

Consider an irreducible factor $F$ that appears both as a factor of $A$
and also in $q$'s denominator, with
multiplicity $m \ge 1 $, so $q = N/(F^m D)$, and we rewrite the Risch equation:

$$A F q' - B q = C$$

$$A F \frac{N' F D - m N F' D - N F D'}{F^{m+1} D^2} - B \frac{N}{F^m D} = C$$

$$A F N' D - m A F' N D - A F N D' - B N D = C D^2 F^{m}$$

$$ - m A F' N D - B N D  = C D^2 F^{m} - A F N' D + A F N D'$$

$$ - (m A F' - B ) N D  = F (C D^2 F^{m-1} - A N' D - A N D')$$

Now, the right hand side of this equation is a multiple of $F$, so the
left hand side must also be a multiple of $F$.  However, $F$ is
irreducible and is relatively prime to both $N$ and $D$, so the only way
the left hand side can be a multiple of $F$ is if $m A F' - B$ is a
multiple of $F$.

Why?  All of these variables
are polynomials in ${\mathbb C}[x]$, so this equation is an equality
between polynomials.  Because ${\mathbb C}[x]$ is a {\it unique factorization domain}, its
polynomials can factor in essentially one way only, so if $F$ factors
the right hand side, it must also factor the left.  If $F$ were not
irreducible, then it might have two factors, one contributed by $N$
and the other contributed by $D$.  It's the irreducibility of $F$,
the unique factorization of polynomials in ${\mathbb C}[x]$, and
our assumption that $N$ and $D$ are relatively prime to $F$
that makes this argument work.

The simplest way to enforce this factorization requirement is to use
the resultant (Theorem \ref{resultant theorem}):

$${\rm res}_x(m A F' - B, F) = 0$$

We calculate this resultant for each irreducible factor $F$ of $A$,
and this gives us $m$, the power to which $F$ appears in $q$'s
denominator.  If this resultant equation has no positive integer
solution, then $F$ can not appear at all in $q$'s denominator.

\end{comment}
