
\setcounter{chapter}{2}
\mychapter{Differential Algebra}

\section{Differential Fields}

The advent of the modern, axiomatized approach to mathematics at the
turn of the twentieth century led directly to the development of
abstract algebra, with its rings and fields, in the 1920s.  By 1940, a
Columbia University professor named J.F. Ritt had proposed the
concepts of {\it differential rings} and {\it differential fields}.
They are exactly analogous to ordinary rings and fields, except that
they are equipped with a third basic operator (addition and
multiplication are the first two), called {\it derivation}.  A
derivation is a unary operator (the other two are binary), which we
shall typically denote by $D$.  Since algebra is fundamentally
concerned with how operators commute with each other, the first
question we are lead to ask are, ``How does derivation commute with
addition and multiplication?''  The answer is to be found in two basic
axioms:

\begin{center}
\begin{supertabular}{l l l r}
   addition law of derivations	& $\forall a,b \in {\cal D},$ & $D(a+b) = Da+Db$ &(D1)\cr
   multiplication law of derivations	& $\forall a,b \in {\cal D},$ & $D(ab) = aDb+bDa$ &(D2)\cr
\end{supertabular}
\end{center}

Neither axiom should come as any great surprise.  After all, these are
just the basic addition and multiplication rules we learned in first
year calculus.  Yet note how they are being presented; not as results
derived from some theorem involving fractions and limits, but as
axioms that are assumed true from the start.  One of the great themes
of differential algebra is that we purge from the subject almost any
mention of limits; for us, derivation is just a mapping in a field
that carries an object $a$ to another object $b$.  Integration, then,
is little more than the inversion of derivation: given an object $b$,
can we find an object $a$ which maps into $b$?

Yet the connection to calculus should be made clear.  Since derivation
(in the calculus sense) obeys these two axioms for derivation (in the
algebra sense), the calculus derivation will always behave as an
algebra derivation, so any theory we develop for the algebra
derivation will apply immediately to the calculus version.

What can we determine from these two axioms?  A surprising lot,
in my opinion.

% \vfill\eject

\theorem\label{basic difalg}

\begin{itemize}
\item $D(0) = 0$
\item $D(1) = 0$
\item $\displaystyle{D({1\over a}) = - {1\over a^2}D(a)}$
\item $D(cx) = c\, D(x)$ if $D(c)=0$
\end{itemize}

\proof

$$D(0) = D(0) + D(0) - D(0) = D(0+0) - D(0) = D(0) - D(0) = 0$$

$$D(1) = D(1\cdot1) = D(1) + D(1)$$

$$D(1) = D(1) + D(1) - D(1) = D(1) - D(1) = 0$$

$$0 = D(1) = D(a\cdot{1\over a}) = {1\over a} D(a) + a D({1\over a})$$

$$ a D({1\over a}) = - {1\over a}D(a)$$

$$ D({1\over a}) = - {1\over a^2}D(a)$$

\endtheorem

It follows immediately from this theorem that our entire prime
subfield, as well as any purely algebraic extension thereof, must map
to zero under derivation.

\theorem

The set of all elements in a differential field which map to zero
under derivation forms a subfield.

\endtheorem

The subfield which maps to zero is called the {\it constant subfield}.
It necessarily includes the prime subfield and any elements algebraic
over the prime subfield, but may include other transcendental elements
as well.  For example, consider ${\bf R}$, the real numbers.  $2$ is
in the prime subfield, so $D(2)=0$; $\sqrt{2}$ is algebraic over the
prime subfield, so $D({\sqrt 2})=0$; $\pi$ is transcendental over the
prime subfield, so doesn't {\it have} to map to zero, but we will
(obviously) set $D(\pi)=0$.  All three elements --- $2$, ${\sqrt 2}$,
$\pi$ --- are in the constant subfield.

\theorem
\label{derivation of an algebraic element}

The derivation of an algebraic extension
is determined uniquely by the derivation of its subfield.

\proof

The derivation of an algebraic element is completely
defined by the subfield's derivation and the element's minimal polynomial.

Given an element $\xi$, let its minimal polynomial be:

$$\sum_i a_i \xi^i = 0$$

Differentiating this polynomial (using the D1 and D2 axioms), we obtain:

$$\sum_i (a_i' \xi^i + i a_i \xi^{i-1} \xi') = 0 $$

$$\sum_i i a_i \xi^{i-1} \xi' = - \sum_i a_i' \xi^i $$

$$\xi' = - {\sum_i a_i' \xi^i \over {\sum_i i a_i \xi^{i-1}}} $$

\endtheorem

The upshot of all this is that our basic D1 and D2 axioms completely
define a derivation both for our prime subfield as well as any purely
algebraic extensions.  It therefore follows that we need only specify
the behavior of a derivation on transcendental elements and we will
have completely defined the derivation.

We will use four types of transcendental elements in our theory:

1. Constants.  $D(c)=0$

2. The distinguished variable of integration.  $D(x)=1$

Since this is an O.D.E. theory, and particularly an integration
theory, we are always integrating with respect to some variable of
integration.  There is no loss of generality in labeling it $x$.  By
setting $D(x)=1$ we establish that our derivation is in fact a
derivative and not a differential.

Incidently, Ritt had already conceived back in the 1940s of equipping
a differential field with multiple derivations, one for each of a set
of independent variables.  This corresponds nicely to what is
needed for a P.D.E. theory.  Thus, given variables $x$, $y$ and $z$,
we could construct derivatives $D_x$, $D_y$ and $D_z$ so that
$D_x(x)=1$, $D_x(y)=0$, $D_x(z)=0$ and so on.  Since our focus is
on integration, I'll have nothing more to say about fields with
multiple derivations.

3. Logarithmic extensions. $D(\theta)={D(\phi)\over{\phi}}$

4. Exponential extensions. $D(\theta)=\theta D(\phi)$

$\phi$, in both of these cases, is some element in the underlying field.

These two extentions clearly correspond to $\theta = \ln\phi$ (in the
logrithmic case) and $\theta = \exp\phi$ (in the exponential case).
The key point I want to made immediately is that these are {\it
transcendental} extensions\ldots and not all logarithms and
exponentials are transcendental!  Transcendental extensions are
defined by exclusion --- any extension that isn't algebraic is
transcendental.  If we're dealing with an algebraic extension, even if
defined using logarithms and exponentials, we have to use our
algebraic theory.

\example Represent $\displaystyle {{4^x+1}\over{2^x+1}}$ in Liouvillian form\label{represent 4^x+1/2^x+1}

There are three ways to do this --- the easy way, the hard way, and
the wrong way.

Let me first note that $4^x = (2^2)^x = (2^x)^2$.  The existence of
this algebraic relationship between $4^x$ and $2^x$ means that we {\it
can not} use two seperate transcendental extensions.  So this:

$${{\theta+1}\over{\phi+1}}; \theta = \exp(x \ln 4); \phi = \exp(x \ln 2)$$

is the {\it wrong} way.

The {\it easy} way is to set up $2^x$ first and then construct $4^x$
as its square:

$${{\phi^2+1}\over{\phi+1}}; \phi = \exp(x \ln 2)$$

You can also do this the {\it hard} way, setting up $4^x$ first and
then using an additional algebraic extension to get its square root,
$2^x$:

$${{\theta+1}\over{\phi+1}}; \theta = \exp(x \ln 4); \phi^2 = \theta$$

See Example \ref{integrate 4^x+1/2^x+1} for the actual integration.

\endexample

That's it!  The basic two differential axioms, algebraic extensions,
fraction fields, and these four types of transcendentals, round out
the entire base algebraic structure we'll need to construct our
theory.  We do need to be careful, though, as the last example
illustrated.  In these simple examples, figuring out which elements
are algebraic and which are transcendental is easy, but in more
complex expressions this may not be obvious.  We'll discuss in Chapter
?? how to test new elements for transcendence.

\begin{sageblocksmall}
from sage.rings.fraction_field_element import is_FractionFieldElement
from sage.rings.polynomial.polynomial_element import is_Polynomial
from sage.rings.polynomial.multi_polynomial import is_MPolynomial

from sage.misc.latex import str_function

class Derivation(SageObject) :

    def __init__(self, parent, generator_map):
        self.generator_map = generator_map
        self.parent = parent

    def _repr_defn(self):
        gm = self.generator_map
        return '\\n'.join(['%s |--> %s'%(i, gm[i]) for i in gm])

    def _repr_(self):
        return 'Derivation of %s\\n  Defn: %s'%(R, '\\n         '.join(self._repr_defn().split('\\n')))

    def _latex_defn(self):
        gm = self.generator_map
        return '\\\\\\\\'.join(['%s & \\\\rightarrow & %s'%(latex(i), latex(gm[i])) for i in gm])

    def _latex_(self):
        return '\\\\begin{array}{rcl}\\\\multicolumn{3}{c}{' + str_function('Derivation of ') + latex(self.parent) + '}\\\\\\\\' + self._latex_defn() + '\\\\end{array}'

    def __call__(self, x):
        gm = self.generator_map
        if is_FractionFieldElement(x):
            n = x.numerator()
            d = x.denominator()
            return (self(n)*d - n*self(d))/(d^2)
        elif is_Polynomial(x):
            var = x.args()[0]
            Dvar = gm[var]
            result = 0
            for power in range(0, x.degree()+1):
                coeff = x[power]
                result = result + power * coeff * var^(power-1) * Dvar
                result = result + self(coeff) * var^power
            return result
        elif is_MPolynomial(x):
            vars = x.args()
            result = 0
            for (monomial, coeff) in x.dict().items():
                for i in range(len(monomial)):
                    power = monomial[i]
                    if power > 0:
                        var = vars[i]
                        Dvar = gm[var]
                        result = result + power * coeff * x.parent().monomial(*monomial) / var * Dvar
                        result = result + self(coeff) * x.parent().monomial(*monomial)
            return result
        elif x.parent() in [ZZ, QQ, AA, QQbar, RR, CC]:
            return 0
        else:
            raise NotImplementedError
\end{sageblocksmall}

\begin{sageblock}
R.<x> = QQ[]

D = Derivation(R, {x: 1})

D(x^2)

R.<x,theta,psi> = QQ[]

D = Derivation(R, {x: 1, theta: 1/x, psi: psi})

D(x*theta*psi)
\end{sageblock}

\definition

An {\bf elementary extension} of a differential field
is a differential extension field constructed using
a finite number of algebraic, logarithmic, and
exponential extensions.

\enddefinition

\definition

A {\bf elementary function} of a single variable $x$ over a specified
field of constants $K$ is a function in an elementary extension of the
rational function field $K(x)$.

\enddefinition

What about sines and cosines, all those arc-functions, raising things
to powers, and all that?  Turns out we can express all those
operations using just our basic extensions.  The key here is Euler's
famous identity $e^{i\theta}=i\sin\theta+\cos\theta$.

\example

Express $\sin x$ in Liouvillian form

Euler's identity immediately gives:

$$\sin x = {-i \,{{e^{ix} - e^{-ix}}\over 2}}$$

Therefore, starting from ${\bf C}(x)$,
we add the exponential extension $\theta = \exp(ix)$,
and conclude that $\sin x$ can be expressed as the rational function:

$${{\theta^2 - 1}\over 2i\theta}$$

in the field ${\bf C}(x,\theta); \theta=\exp(ix)$.

\endexample

If trigonometric functions can be represented using complex
exponentials, then it should come as no real surprise that inverse
trigonometric functions can be represented with complex logarithms.

\example Represent $\arcsin x$ in Liouvillian form

Let's start with Euler's identity and take its logarithm:

$$e^{i\theta}=i\sin\theta+\cos\theta$$

$$i\theta=\ln(i\sin\theta+\cos\theta)$$

Now, if $\theta = \arcsin x$, then $x = \sin \theta$, and we can use
the basic $\sin^2 \theta + \cos^2 \theta = 1$ identity to compute
$\cos \theta = \sqrt{1-\sin^2\theta} = \sqrt{1-x^2}$.  Substituting above:

$$i\theta=\ln(i x+\sqrt{1-x^2})$$

$$\theta=-i\ln(i x+\sqrt{1-x^2})$$

$$\arcsin x=-i\ln(i x+\sqrt{1-x^2})$$

Thus, we need first an algebraic extension to construct $\phi = \sqrt{1-x^2}$,
followed by a logarithm extension to construct $\arcsin x = -i\ln(ix+\phi)$.

\endexample

I think the details of further constructions along these lines are
straightforward enough that I will simply summarize them in a table.

\vfill\eject

\mysection{Liouvillian Forms}


\def\sech{{\rm sech}}
\def\csch{{\rm csch}}

\begin{center}
\begin{tabular}{c c c c @{\bigskip}}
Expression & \multicolumn{1}{c}{Liouvillian Form} &
Expression & \multicolumn{1}{c}{Liouvillian Form} \\
\hline
& \\
$f^g$ & $\displaystyle e^{\,g \ln f}$ &
 & \\
$\sin x$ & $\displaystyle {-i \,{{e^{ix} - e^{-ix}}\over 2}}$ \vbox to20pt{}&
 $\sinh x$ & $\displaystyle {{e^{x} - e^{-x}}\over 2}$ \vbox to20pt{} \\
$\cos x$ & $\displaystyle {{e^{ix} + e^{-ix}}\over 2}$ &
 $\cosh x$ & $\displaystyle {{e^{x} + e^{-x}}\over 2}$ \vbox to20pt{} \\
$\tan x$ & $\displaystyle {-i \,{{e^{ix}-e^{-ix}}\over {e^{ix}+e^{-ix}}}}$ &
 $\tanh x$ & $\displaystyle {{e^{x}-e^{-x}}\over {e^{x}+e^{-x}}}$ \\

$\sec x$ & $\displaystyle {2\over{e^{ix} + e^{-ix}}}$ &
 $\sech\, x$ & $\displaystyle {2\over{e^{x} + e^{-x}}}$ \vbox to20pt{} \\
$\csc x$ & $\displaystyle {{2i}\over{e^{ix} - e^{-ix}}}$ \vbox to20pt{}&
 $\csch\, x$ & $\displaystyle {2\over{e^{x} - e^{-x}}}$ \vbox to20pt{} \\
$\cot x$ & $\displaystyle {i \,{{e^{ix}+e^{-ix}}\over {e^{ix}-e^{-ix}}}}$ &
 $\coth x$ & $\displaystyle {{e^{x}+e^{-x}}\over {e^{x}-e^{-x}}}$ \\

$\arcsin x$ & $\displaystyle -i \,\ln (ix + \sqrt{1-x^2})$ &
 $\sinh^{-1} x$ & $\displaystyle \ln (x + \sqrt{x^2+1})$ \\
$\arccos x$ & $\displaystyle -i \,\ln (x + i\sqrt{1-x^2})$ &
 $\cosh^{-1} x$ & $\displaystyle \ln (x + \sqrt{x^2-1})$ \\
$\arctan x$ & $\displaystyle {1\over2}\,i\,\ln {{ix-1}\over{ix+1}}$ &
 $\tanh^{-1} x$ & $\displaystyle {1\over2} \ln {{1+x}\over{1-x}}$ \\

$\sec^{-1} x$ & $\displaystyle -i \,\ln {{1 + i\sqrt{x^2-1}}\over{x}}$ &
 $\sech^{-1} x$ & $\displaystyle {1\over2} \ln {{1+\sqrt{1-x^2}}\over{1-\sqrt{1-x^2}}}$ \\
$\csc^{-1} x$ & $\displaystyle -i \,\ln {{i + \sqrt{x^2-1}}\over{x}}$ &
 $\csch^{-1} x$ & $\displaystyle {1\over2} \ln {{\sqrt{1+x^2}+1}\over{\sqrt{1+x^2}-1}}$ \\
$\cot^{-1} x$ & $\displaystyle {1\over2}\,i\,\ln {{i+x}\over{i-x}}$ &
 $\coth^{-1} x$ & $\displaystyle {1\over2} \ln {{x+1}\over{x-1}}$ \\

\end{tabular}
\end{center}

\vfill\eject

\section{Liouville's Theorem}

The next problem we must confront is to limit the number of possible
fields in which we can find solutions to our problem.  So far, we have
seen how to construct an algebraic system to express any elementary
function, but there are an infinity of such systems.  Searching them
exhaustively for the solution to a given integral is out of the
question.  Fortunately, it's been known for almost 200 years that
there are severe restrictions on what extensions can appear in an
integral above and beyond those used in the original integrand.

For example, consider the expression $e^x$.  Differentiating it
yields, well, $e^x$.  Now the key thing to note is that the
exponential does not disappear after differentiation.  This, in fact,
is a general property of exponentials --- differentiation never makes
them disappear.  They can change around, to be sure,
${d\over dx}e^{2x}=2e^{2x}$, but notice that the exponential is still
present in the result.  Therefore, since the solution to our integral
must differentiate into the original integrand, we conclude that no
new exponentials can appear in the integral beyond those in the
integrand.  If there were new exponentials in the result, then they
would have to appear in the integrand as well, since they can never
disappear under differentiation.

The same thing happens with roots.  Differentiate $\sqrt{x}$ and you
get ${1\over{2\sqrt{x}}}$.  This time the root moves from the
numerator to the denominator, but again, it doesn't completely
disappear.  This is a general property of roots, algebraic extensions
in general, in fact.

Logarithms are different, though.  Differentiate $\ln x$ to get
$1\over x$.  The logarithm is gone.  So new {\it logarithms} can
appear in integrals, because they can disappear under differentiation
to recover the original integrand.  Even here, though, there are
important restrictions.  The logarithms have to appear with constant
coefficients (because something like $x\ln x$ would differentiate into
$1 + \ln x$), can not appear in powers or in denominators (${d\over
dx} \ln^2x = 2{\ln x\over x}$), and can not be nested (${d\over dx}
\ln(\ln x) = {1\over{x\ln x}}$).

% Of course, all of this is hand-waving so far, but I hope that it
% provides context and concrete examples to understand what has become
% known as {\it Liouville's Theorem} --- the only new extensions that
% can appear are simple logarithms.  Let's nail this down, now.

These examples are all special cases of {\it Liouville's Theorem} ---
the only new extensions that can appear in an integral are simple
logarithms with constant coefficients.  Let's begin by stating
and proving some basic properties of our three basic types
of extensions.

\theorem\label{basic logarithmic properties}
Let $E=K(\theta)$ be a simple transcendental logarithmic extension of
a differential field $K$ with the same constant subfield as $K$, let
$p=\sum p_i \theta^i$ be a polynomial in $K[\theta]$, and let $r =
a/b$ be a rational function in $K(\theta)$ ($a, b \in K[\theta]$).
Then:

\begin{enumerate}
\item If $p$'s leading coefficient is constant ($p_n' = 0$), then ${\rm Deg}_\theta\, p' = {\rm Deg}_\theta\, p - 1$
\item If $p$'s leading coefficient is not constant ($p_n' \ne 0$), then ${\rm Deg}_\theta\, p' = {\rm Deg}_\theta\, p$
\item If $p$ is monic and irreducible, then $p' \nmid p$
\item If an irreducible factor appears in $r$'s denominator with multiplicity
$m$, then it appears in $r'$'s denominator with multiplicity $m+1$
\item $r' \in K$ if and only if $r$ has the form $c\theta + k$, where $c$ is a constant
\end{enumerate}

\proof

The first two statements follow easily from considering $p'$:

$$p'=\sum_{i=0}^n (p_i' \theta^i + i p_i \theta' \theta^{i-1}) = \sum_{i=0}^n
\left(p_i' + \left(i+1\right)p_{i+1} \theta'\right) \theta^i$$

Note that since $K(\theta)$ is a logarithmic extension, $\theta'
\in K$, so for all $i$ the entire expression $(p_i' + (i+1)p_{i+1} \theta')$
is in $K$.  In particular, since $p_{n+1}$ is zero, the $n^{\rm th}$
coefficient of $p'$ is just $p_n'$ and the $\theta$-degree of $p'$
will be $n$ if $p_n'$ is non-zero.  On the other hand, if $p_n'$ is
zero, then the $n-1^{\rm th}$ coefficient of $p'$ is $(p_{n-1}' + n
p_n \theta')$ which would be zero only if $\theta' =
-\frac{p_{n-1}'}{n p_n} = (-\frac{p_{n-1}}{n p_n})'$ (by Theorem
\ref{basic difalg} since $p_n$ is constant), which implies
an algebraic relationship between $\theta$ and $-\frac{p_{n-1}}{n
p_n}$ (specifically, they differ only by a constant, which must be in
$K$), contradicting the transcendence of $E$ over $K$.

Next, if $p$ is monic and irreducible, then ${\rm Deg}_\theta\, p' =
{\rm Deg}_\theta\, p - 1$, and no lower degree polynomial can divide
an irreducible polynomial, establishing the third claim.

Now consider a rational function $r=a(\theta)/b(\theta)$ in its
normalized form, so $\gcd(a,b) = 1$ and $b$ is monic.  Now we can
factor $b$ into irreducible factors ($b=\prod b_i(\theta)^{m_i}$) and
expand $r$ using partial fractions (Section \ref{sec:Partial Fractions
Expansion}):

$$r = a_0(\theta) + \sum_{i=1}^\mu \sum_{j=1}^{m_i} \frac{a_{ij}(\theta)}{b_i(\theta)^j}$$

where $a_0, a_{ij}, b_i \in K[\theta]$ and ${\rm Deg}_\theta\, a_{ij} < {\rm
Deg}_\theta\, b_i$.  Now let's differentiate:

$$r' = a_0'(\theta) + \sum_{i=1}^\mu \sum_{j=1}^{m_i} \left[
\frac{a'_{ij}(\theta)}{b_i(\theta)^j} - \frac{j\, a_{ij}(\theta)\,
b_i'(\theta)}{b_i(\theta)^{j+1}} \right]$$

$a_{ij}$ does not divide $b_i$ (since ${\rm Deg}_\theta\, a_{ij} <
{\rm Deg}_\theta\, b_i$, and we proved above that $b'_i$ does not
divide $b_i$ (since $b_i$ is monic and irreducible), so there is
exactly one term on the right hand side with $b_i(\theta)^{m_i + 1}$
in its denominator and no other terms with higher powers.  Therefore,
$r'$ must have a $b_i(\theta)^{m_i +1}$ in its denominator, establishing
the fourth claim.

Finally, since the hypothesis of the fifth claim states that $r'$ is in
$K$, it can not have any $\theta$ terms in its denominator (or
anywhere else), so there can not be any $b_i(\theta)$ factors, and $r$
must be a polynomial.  Futhermore, our first two claims imply that if
${\rm Deg}_\theta\, r' = 0$ (since $r'\in K$), then ${\rm
Deg}_\theta\, r$ can be at most 1, and its leading coefficient must be
constant.

\endtheorem

\theorem\label{basic exponential properties}
Let $E=K(\theta)$ be a simple transcendental exponential extension of
a differential field $K$ with the same constant subfield as $K$,
let $p=\sum p_i \theta^i$ be a polynomial in $K[\theta]$,
and let $r=a/b$ be a rational function in $K(\theta)$
($a, b \in K[\theta]$).  Then:

\begin{enumerate}
\item ${\rm Deg}_\theta\, p' = {\rm Deg}_\theta\, p$
\item $p' \mid p$ if and only if $p$ is monomial (i.e, has the form $p_i \theta^i$)
\item If an irreducible factor other than $\theta$ appears in $r$'s
denominator with multiplicity $m$,
then it appears in $r'$'s denominator with multiplicity $m+1$
\item $r' \in K$ if and only if $r \in K$
\end{enumerate}

\proof

Again,

$$p' = \sum_{i=0}^n (p_i' \theta^i + i p_i \theta' \theta^{i-1})$$

This time, however, $\theta' = k'\theta$, so

$$p' = \sum_{i=0}^n (p_i' + i p_i k') \theta^i$$

Assume that one of these coefficients, say $(p_i' + i p_i k')$, was
zero but $p_i$ was non-zero.  Then $D(p_i \theta^i) = (p_i' + i p_i
k')\theta^i = 0$, so $p_i \theta^i$ would be a constant, which must be in $K$,
contradicting the transcendence of $E$.  Therefore, none of these
coefficients can be zero, establishing the first claim.

To establish the second claim, assume first that $p' \mid p$.  Since
$p'$ has the same degree as $p$ (by the first claim), it can only
divide $p$ if it has the form $mp$, where $m \in K$.  Equating
coefficients of $\theta$ in the above sums leads us to conclude that

$$m = (\frac{p_i'}{p_i} + i k')$$

If $p$ was not monomial, then all of its coefficients must
yield the same value for $m$, i.e,

$$m = (\frac{p_i'}{p_i} + i k') = (\frac{p_j'}{p_j} + j k')$$

$$p_i' p_j - p_i p_j' + (i - j) k' p_i p_j = 0$$

$$\frac{p_i' p_j - p_i p_j'}{p_j^2} + (i - j) k' \frac{p_i}{p_j} = 0$$
$$\left(\frac{p_i}{p_j}\right)' + (i - j) k' \frac{p_i}{p_j} = 0$$

Then $D(\frac{p_i}{p_j} \theta^{j-i}) = \left(\frac{p_i}{p_j}\right)'
+ (i - j) \frac{p_i}{p_j} k' = 0$, again contradicting the
transcendence of $E$ over $K$.  So $p$ must be monomial.

Conversely, if $p$ is monomial, say $a\theta^n$, then $p' = (a' +
n a k') \theta^n = \frac{a' + n a k'}{a} p$ and $p' \mid p$.

To prove the final two claims, we proceed as before, expanding $r$
using partial fractions:

$$r = a_0(\theta) + \sum_{i=1}^\mu \sum_{j=1}^{m_i} \frac{a_{ij}(\theta)}{b_i(\theta)^j}$$

and taking the derivative:

$$r' = a_0'(\theta) + \sum_{i=1}^\mu \sum_{j=1}^{m_i} \left[
\frac{a'_{ij}(\theta)}{b_i(\theta)^j} - \frac{j\, a_{ij}(\theta)\,
b_i'(\theta)}{b_i(\theta)^{j+1}} \right]$$

$\theta$ is the only irreducible monomial, so if a $b_i$ is not
$\theta$, then it will not be canceled by $b_i'$, and again we'll have
a single term on the R.H.S. with $b_i^{j+1}$ in the denominator, so
the L.H.S. must also have a $b_i^{j+1}$ in its denominator.

This time, however, $b_i'$ can divide $b_i$ if $b_i$ is monomial.
When $r'$ is in $K$', all other possibilities are excluded as before,
so $r$ must now have the form:

$$r = \sum_{i=-m}^n r_i \theta^i$$

where $r_i \in K$.  We've already established that if $r_i$ is
non-zero, then the corresponding term in the derivative
is also non-zero, so the only way for $r'$ to be in $K$ is if
$r$ is in $K$.

\endtheorem

\example Let $p = x e^x$.  Then
$\frac{d}{dx} x e^x = e^x + x e^x = (x+1) e^x = \frac{x+1}{x} e^x$.

We start with the rational function field $K = {\mathbb C}(x)$, and
extend by the transcendental exponential $\theta = \exp(x)$ to form
the ring $K[\theta]$.  Both $p$ and $p'$ are in $K[\theta]$;
$p=x\theta$ is monomial (in $\theta$); note that $\frac{x+1}{x} \in
K$, so $p' \mid p$ in this ring.

\endexample

\theorem\label{basic algebraic properties}

Let $A$ be an algebraic extension of a differential field $K$ with the
same constant subfield as $K$, let $\sigma$ be an automorphism of
$A/K$, and let $a$ be an element of $A$.

\begin{enumerate}
\item $D(\sigma x) = \sigma(D x)$,
\item $\Tr(D x) = D(\Tr x)$,
\item $\Tr(\frac{D x}{x}) = \frac{\N(x)'}{\N(x)}$
\item $a' \in K \leftrightarrow a \in K$.
\end{enumerate}

\proof

1. Consider an automorphism $\sigma$ of $A/K$, i.e, an automorphism of $A$
that fixes the differential field $K$, so that $\sigma x = x$ for
$x \in K$.  Writing the minimal polynomial of $x$ as $\sum_i a_i x^i =
0$, applying $\sigma$ to this equation, and remembering that
automorphism commutes with multiplication and addition and that
$a_i \in K$, we obtain $\sum_i a_i (\sigma x)^i = 0$, i.e, $\sigma x$
has the same minimal polynomial as $x$; we say that $\sigma x$
is a {\it conjugate} of $x$.

Theorem \ref{derivation of an algebraic element} now gives us the derivation of $\sigma x$:

$$D(\sigma x) = - {\sum_i a_i' (\sigma x)^i \over {\sum_i i a_i (\sigma x)^{i-1}}} $$

Applying the operators in the other direction, however, and again using
the fact that automorphism commutes with our field operators, we obtain:

$$\sigma(D x) = \sigma\left(- {\sum_i a_i' x^i \over {\sum_i i a_i x^{i-1}}} \right)
= - {\sum_i a_i' (\sigma x)^i \over {\sum_i i a_i (\sigma x)^{i-1}}} $$

i.e, $D(\sigma x) = \sigma(D X)$; automorphisms that fix the base field
of an algebraic extension commute with derivation.

2. Now let's consider how an automorphism $\sigma$ of $A/K$ interacts with Tr.  Remember that
trace, in a Galois extension, can be written as a sum over all
automorphisms that fix the base field:

$${\rm Tr\,} x = \sum_\sigma \sigma x$$

We extend $A$, if necessary, into a Galois extension, and use
the commutation relationship we just proved to establish
that trace commutes with derivation:

$$D(\Tr x) = D\left(\sum_\sigma \sigma x\right) = \sum_\sigma D(\sigma x)
= \sum_\sigma \sigma(D x) = \Tr(D x)$$

3. Using the commutation relationship we just proved, along with the definitions of $\Tr$ and $\N$:

$$\Tr(\frac{D x}{x}) = \sum_\sigma \sigma\left( \frac{D x}{x} \right) = \sum_\sigma \frac{\sigma D x}{\sigma x}
= \sum_\sigma \frac{D \sigma x}{\sigma x} = \frac{D \prod_\sigma \sigma x}{\prod_\sigma \sigma x} = \frac{D(\N(x))}{\N(x)}$$

4. The right-to-left implication is obvious (since differential fields
are closed under derivation), so we need only to prove the
left-to-right implication.

Consider $a$, with $D a \in K$,
so $\Tr(D a) = n D a$, where $n$ is the degree of the algebraic extension,
by Theorem \ref{trace in underlying field}.
It follows that
$$D a = \frac{1}{n} \Tr(D a) = \frac{1}{n} D(\Tr a)$$

Since $\Tr a \in K$, we have identified an
element in $K$ with the same derivation as $a$, which therefore can
differ from $a$ solely by an additive constant.  Since $A$ and $K$ have the same
constant subfield, all of our constants are in $K$, so $a$ is
therefore also in $K$.

\endtheorem

\example

Explain the ``disappearance'' of the square root in:

$$\int{1\over\sqrt{1-x^2}} = \arcsin x$$

Finding $\arcsin x$ in the table, we see that:

$$\arcsin x = -i \,\ln (ix + \sqrt{1-x^2})$$

That's where it went!  It ``disappeared'' into the complex logarithm
that $\arcsin x$ is formed from.  New logarithms, of course, are
acceptable.  Notice that the new logarithm has a constant coefficient
($-i$), is not nested, and appears to the first power.

\endexample

Notice the extra condition on the algebraic extension, that the
extension has to preserve the constant subfield.  The theorem would
fail without this condition, as shown by numerous examples of roots
appearing in integrals where only rational numbers were needed in the
integrand.  The simplest way to handle this situation is to use an
algebraically closed constant subfield (like ${\mathbb C}$), but
this is not always practical.

\example

$$\int \frac{1}{x^2-2} dx = \int \frac{1}{2\sqrt{2}} \left[ \frac{1}{x-\sqrt{2}} - \frac{1}{x+\sqrt{2}} \right] dx$$
$$= \frac{1}{2\sqrt{2}} \left[ \ln(x-\sqrt{2}) - \ln(x+\sqrt{2}) \right]$$

This integrand can be expressed in ${\mathbb Q}(x)$, but the integral
requires ${\mathbb Q}(x,\xi,\theta,\psi)$; $\xi$ is algebraic
with minimal polynomial $\xi^2-2=0$; $\theta$ and $\psi$ are
logarithmic transcendental with $\theta' = 1/(x-\xi)$
and $\psi' = 1/(x+\xi)$.

\endexample

Finally, we want to prove the full Liouville theorem, establishing
that the only new extensions that can appear in an integral are
logarithmic ones.

\begin{comment}
This is a major tool in our program of symbolic
integration, since it severely limits the possible extensions that
need to be searched for an integral.  Indeed, if we could not
limit the appear of new extensions, it is unlikely that we
could completely and systemically evaluate integrals.

The structure theorems above already establish a simplified version of
the Liouville theorem for single extensions.  We need a version of the
Liouville theorem that holds over any number of extensions, so
an induction step is required.
\end{comment}

\theorem\label{weak Liouville theorem} (Liouville)
Let $L$ be an elementary extension of a differential field $K$ with
the same constant subfield as $K$.  Then $\forall l \in L$, $l' \in K$
iff $l$ has the form:

$$k + \sum_{i=1}^n c_i \theta_i$$

where $k\in K$, $K(\theta_i)$ are simple logarithmic extensions of $K$ and $c_i$
are constants.

\proof

By the definition of an elementary extension, $L$ has the form $K(t_1,\ldots,t_n)$
where each $t_i$ is a simple elementary extension of $K(t_1,\ldots,t_{i-1})$.

We'll proceed by induction on the number of extensions $n$.  Theorems \ref{basic logarithmic properties}(5),
\ \ref{basic exponential properties}(4), and \ref{basic algebraic properties}(4)
establish the theorem for $n=1$.  So assume that the theorem is true
for all $i<n$.

Let $M = K(t_1)$, so $L = M(t_2,\ldots,t_n)$,
and the induction hypothesis implies that if $l' \in M$,
then $l$ has the form:

$$l = m_0 + \sum c_i \theta_i$$

where $m_0 \in M$ and $M(\theta_i)$ are simple logarithmic extensions of $M$.

$$l' = m_0' + \sum c_i \frac{m_i'}{m_i}$$

$l' \in K$, and $m_0$ and the various $m_i$ are rational
functions in $K(t_1)$.  We can use our basic logarithm identities:

$$\frac{(ab)'}{ab} = \frac{a'}{a} + \frac{b'}{b} \qquad\qquad
\frac{(\frac{1}{a})'}{\frac{1}{a}} = \frac{-\frac{a'}{a^2}}{\frac{1}{a}} = - \frac{a'}{a}$$

to reduce to the case where the $m_i$ (except $m_0$) are all irreducible
polynomials, so let's consider our three cases:

\begin{enumerate}

\item $K(t_1)$ is logarithmic over $K$.

In this case, Theorem \ref{basic logarithmic properties}(4) states
that if $m_0$ has a non-trivial denominator with an irreducible factor
$p$, then $p$ appears in $m_0'$'s denominator with multiplicity at
least two.  Since $l' \in K$, this implies that the sum must
contribute a denominator with the same multiplicity in order to
achieve cancellation, so $p$ must be one of the $m_i$'s.  However,
since $p$ is irreducible, Theorem \ref{basic logarithmic
properties}(4) implies that the multiplicity of $p$ in the sum's
denominator can be no more than one, so $m_0$ must be a polynomial.

Futuremore, there is no cancellation between a normal irreducible
polynomial and its derivative, so none of the $m_i$'s can be
polynomials in $K[t_1]$; they must exist in $K$, since otherwise
$l'$ would have a non-trivial denominator in $K(t_1)$,
and by hypothesis, $l' \in K$.

Finally, Theorem \ref{basic logarithmic properties}(5) states
that $m_0$ must have the form $k_0 + c_0 t_1$.  In other
words, a simple logarithm extension can contribute a single
term to the sum in the statement of the theorem.

\item $K(t_1)$ is exponential over $K$.

This case is similar to the logarithmic one, except that we must now
consider the possibility of special polynomials in the $m_i$'s.
Actually, there is only one special irreducible polynomial, $t_1$
itself.  If one of the $m_i$'s was $t_1$, then it would cancel
with its derivative as follows:

$$\frac{t_1'}{t_1} = k'$$

Since both $l'$ and $k'$ are in $K$, we can collect them together as follows:

$$l' - c_1 k' = m_0' + \sum c_i \frac{m_i'}{m_i}$$

and proceed with the proof as before.  This time, however,
Theorem \ref{basic exponential properties}(4) tells us that
$m_0$ can only have the form $k_0$, so exponential
extensions contribute nothing to the sum in the statement
of the theorem.

\item $M = K(t_1)$ is algebraic over $K$

Applying the trace map to our induction equation:

$$\Tr(l') = \Tr(m_0') + \sum c_i \Tr \left( \frac{m_i'}{m_i} \right)$$

Since $l' \in K$, $\Tr(l') = n l'$, where $n$ is the degree of the
algebraic extension $K(t_1)$ over $K$, and:

$$n l' = \Tr(m_0)' + \sum c_i \frac{\N(m_i)'}{\N(m_i)}$$

$$l' = \left[ \frac{\Tr(m_0)}{n} \right]' + \sum \frac{c_i}{n} \frac{\N(m_i)'}{\N(m_i)}$$

Setting $k_0 = \frac{\Tr(m_0)}{n}$ and $k_i = \N(m_i)$, we see that $l'$
can be written:

$$l' = k_0' + \sum \frac{c_i}{d} \frac{k_i'}{k_i}$$

establishing that $l$ has the form required by the theorem.


\end{enumerate}


\begin{comment}

Let $M = K(t_1,\ldots,t_{n-1})$,
so $L = M(t_n)$ is a simple elementary extension of $L$, and the
theorem holds for $M$.

If $L = M(t_n)$ is either an exponential or an algebraic extension
of $M$, then Theorem \ref{basic exponential properties}(4) or
Theorem \ref{basic algebraic properties}(4) establishes that
for $l \in L$, if $l' \in M$ then $l \in M$.  Since $l' \in K$
implies $l' \in M$, we conclude that $l \in M$ and the
theorem holds by induction.

The other case we must consider is when $L = M(t_n)$ is an
logarithm extension of $M$.  In this case, we again know
that $l' \in K$ implies that $l' \in M$, and Theorem
\ref{basic logarithmic properties}(5) tells us that
$l$ must have the form

$$l = m + c t_n \qquad l' = m' + c \frac{m_1'}{m_1}$$

\end{comment}


\begin{comment}

Since $L$ is formed from $K$ by a finite number of simple extensions,
consider the last extension and call it $\theta$, i.e, $L=M(\theta)$
where $K \subset M \subset L$, and $\theta$ is either algebraic,
logarithmic, or exponential over $M$.

Since $l' \in K$, $l' \in M$.  If
$\theta$ were either exponential or algebraic, then by Theorems
\ref{basic exponential properties} and \ref{basic algebraic properties}
$l$ would have to be in $M$.  On the other hand, if $\theta$ were
logarithmic, then by Theorem \ref{basic logarithmic properties} $l$
must have the form $c\theta + m$, where $m\in M$.  Applying this
argument inductively leads us to conclude that $l$ must have the
form...  (FIX AND FINISH THIS PROOF)

\end{comment}

\endtheorem
