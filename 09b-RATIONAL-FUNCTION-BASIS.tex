
\section{Basis for all Rational Functions}

The first kind of basis we're interested in, a {\it basis for all
rational functions}, is one than spans the entire ${\cal C}(x,y)$ field
as a ${\cal C}(x)$-module.
In other words, we're looking for a basis $\{b_1, b_2,
... b_n\}$ so that everything in ${\cal C}(x,y)$ can be expressed
in the form:

	$$ a_1 b_1 + a_2 b_2 + ... + a_n b_n; a_i \in {\cal C}(x) $$

Such a basis will always have $n$ elements, where $n$ is the degree of
the ${\cal C}(x,y)$ extension over ${\cal C}(x)$, and can be most
conveniently characterized using its {\it conjugate matrix}:

\definition

The {\bf conjugates} of a rational function $\eta(x,y)$ in ${\bf
C}(x,y)$ are the functions formed by replacing $y$ with its conjugate
values.

The {\bf trace} of a rational function $\eta(x,y)$ is the sum of
its conjugates:

$${\rm T}(\eta(x,y)) = \sum_i \eta(x,y_i)$$

The {\bf norm} of a rational function $\eta(x,y)$ is the product of
its conjugates:

$${\rm N}(\eta(x,y)) = \prod_i \eta(x,y_i)$$

Both the trace and norm, as symmetric functions in $y_1,...,y_n$, are
functions in ${\bf C}(x)$.

The {\bf conjugate matrix} ${\bf M}_\omega$ of $n$ elements $\omega_i$
in ${\cal C}(x,y)$, where $n$ is the degree of ${\cal C}(x,y)$ over
${\cal C}(x)$, is the matrix whose each row consists of the $n$
conjugate values of a single element, and whose $n$ rows are formed in
this way from the $n$ elements.

A set of $n$ elements $\omega_i \in {\bf C}(x,y)$ form a {\bf rational
function basis} for ${\bf C}(x,y)$ if the determinant of their
conjugate matrix is non-zero: $|{\bf M}_\omega| \ne 0$

\enddefinition

\definition

For any function $\eta \in {\bf C}(x,y)$ and any rational function
basis $\omega_i$, the {\bf trace vector}
${\bf T}_{\eta/\omega} = \Big({\rm T}(\eta \omega_i)\Big)$ 
of $\eta$ relative to $\omega$
is formed from the
traces of the $n$ products of $\eta$ with the $n$ functions
$\omega_i$.

The {\bf conjugate vector} ${\bf C}_\eta = (\eta(x,y_i))$ is formed from the
$n$ conjugates of $\eta$.

\enddefinition

\theorem
\label{function is zero if trace vector is zero}

For any function $\eta \in {\bf C}(x,y)$ and any rational function
basis $\omega_i$, if ${\bf T}_{\eta/\omega}$ is the zero vector,
then $\eta$ is zero.

\proof

${\bf T}_{\eta/\omega}$, ${\bf M}_\omega$ and ${\bf C}_\eta$
satisfy the matrix equation

$${\bf T}_{\eta/\omega} = {\bf M}_\omega {\bf C}_\eta$$

since each row of this matrix equation has the form

$$ {\rm T}(\eta \omega_i) = \sum_j \omega_i(x,y_j)\eta(x,y_j) $$

Since ${\bf M}_\omega$ is invertible (since its determinant is
non-zero), if ${\bf T}_{\eta/\omega}$ is identically zero, then so must be
${\bf C}_\eta$, and $\eta$ is the first element in ${\bf C}_\eta$.

\endtheorem

\theorem
\label{|M| != 0 implies C(x) basis}

A rational function basis $\omega_i$ spans ${\bf C}(x,y)$ as
a ${\bf C}(x)$-module. ([Bliss], Theorem 19.1)

\proof

Note that when we multiply ${\bf M}_\omega$ by its transpose ${\bf
M}_\omega^T$, the $ij^{\rm th}$ element of ${\bf M}_\omega{\bf
M}_\omega^T$ is:

$$ \sum_k \omega_i(x, y_k)\omega_j(x, y_k) = {\rm T}(\omega_i \omega_j)$$

Since $|{\bf M}_\omega|$ is non-zero, $|{\bf M}_\omega^T|$ is
non-zero, and $|{\bf M}_\omega{\bf M}_\omega^T|$ is non-zero, so given
any function $\eta \in {\bf C}(x,y)$, we can solve the following
equation for ${\bf R}$:

$${\bf T}_\eta = {\bf M}_\omega {\bf M}_\omega^T {\bf R}$$

each of row of which reads:

$$ {\rm T}(\eta \omega_i) = \sum_j {\rm T}(\omega_i \omega_j) r_j $$

Since both ${\bf T}_\eta$ and ${\bf M}_\omega{\bf M}_\omega^T$ are composed of
nothing but traces, they exist in ${\bf C}(x)$, so ${\bf R}$ must also
exist in ${\bf C}(x)$ and its elements therefore commute with the
trace:

$$ {\rm T}(\eta \omega_i) = \sum_j {\rm T}(r_j \omega_j \omega_i) $$

Since the trace of a sum is the sum of the traces:

$$ {\rm T}(\eta \omega_i) = {\rm T}(\sum_j r_j \omega_j \omega_i) $$
$$ {\rm T}((\eta - \sum_j r_j \omega_j) \omega_i) = 0 $$

which implies that $\eta = \sum_j r_j \omega_j$, by Theorem
\ref{function is zero if trace vector is zero}, and since we've
already shown that the $r_j$ are rational functions in ${\bf C}(x)$,
this proves the theorem.

\endtheorem

Let me illustrate with a simple example.

\example

Consider the basis $\{1, y\}$ over the field ${\cal C}(x,y); y^2=x$.
The conjugate value of $y$ is $-y$ (PROVE THIS), so the conjugate
matrix is:

$$C=\left(\begin{matrix}1&1\cr y&-y\cr\end{matrix}\right)$$

and its determinant:

$$\det C=\left|\begin{matrix}1&1\cr y&-y\cr\end{matrix}\right| = -2y$$

Since $-2y$ is not zero, we conclude that $\{1, y\}$ is a basis
for all rational functions over ${\cal C}(x,y); y^2=x$.

\endexample

Notice that I didn't ask whether $-2y$ was zero at some place in the
field.  The determinant of the conjugate matrix can be zero at certain
places; in fact, often is.  It just can't be {\it identically} zero;
i.e, it can't be zero {\it everywhere}.  If this isn't clear, reread
Theorems \ref{function is zero if trace vector is zero} and \ref{|M|
!= 0 implies C(x) basis}, noting that all the matrices are defined
over the {\it fields} ${\bf C}(x)$ and ${\bf C}(x,y)$, where the only
zero element is 0.

