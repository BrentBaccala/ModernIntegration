
\mychapter{Notes}

For a while I was thinking that the product of {\it prime} ideals is
equal to their {\it intersection}.  This is true in principal ideal
domains, but not in general.

For example, consider $I=(x,z)$ and $J=(x+z)$ in $K[x,z]$.
Now, $x+z \in I \cap J$, but $x+z \notin I \cdot J$.

Sage was useful in puzzling this out:

\begin{sageblock}[notes]
R.<x,z> = QQ[];

I = Ideal(x,z);
J = Ideal(x+z);

I.is_prime()
J.is_prime()

I.intersection(J) == I*J
\end{sageblock}

Looking at the primary decomposition, we see that the product is
smaller than the intersection, because there's an extra ideal that
needs to be intersected (the original ideal is the intersection of the
ideals in its primary decomposition).  Sage's comparison operator
for ideals also shows us that the product is contained in the
intersection.

\begin{sageblock}[notes]
I.intersection(J).primary_decomposition()
(I*J).primary_decomposition()

I.intersection(J) > I*J
\end{sageblock}

So now it's a question of finding something in the intersection that
isn't in the product.  The ideal quotient isn't useful for this,
probably because of its Zariski closure property.

\begin{sageblock}[notes]
I.intersection(J).quotient(I*J)
\end{sageblock}

\vfill\eject

\begin{maximablock}
diff(sqrt(x^4+1),x);
diff(%,x);
diff(%,x);
diff(%,x);

diff(sqrt(x^3+1),x);
diff(%,x);
diff(%,x);
\end{maximablock}

\vfill\eject


\mysection{Valuations}
\qquad [van der Waerden], \S18.1

A {\it valuation} is a generalization of the absolute value.  A {\it
valuation} is a mapping $\phi$ from a field ${\bf K}$ to an ordered
field ${\cal R}$ (typically the reals) obeying the following axioms:

\begin{center}
\begin{supertabular}{l l l r}
   positivity	& $\forall a \in {\bf K},$ & $\phi(a) \ge 0$ &(V1)\cr
   definiteness & $\forall a \in {\bf K},$ & $\phi(a) > 0 \Longleftrightarrow a \ne 0$ &(V2)\cr
   homomorphism (on the multiplicative group) & $\forall a,b \in {\bf K},$ & $\phi(ab) = \phi(a)\phi(b)$ &(V3)\cr
   subadditivity (or triangle inequality) & $\forall a,b \in {\bf K},$ & $\phi(a+b) \le \phi(a) + \phi(b)$ &(V4)\cr
\end{supertabular}
\end{center}

A moment's thought will show that the standard absolute value on the
reals obeys these axioms, as does the modulus on the complex field.
Valuations are similar to norms, except that norms are defined on
vector spaces, while valuations are defined on fields.

A valuation is said to be {\it non-Archimedian} if it also satisfies
the following axiom, stronger than V4:

\begin{center}
\begin{supertabular}{l l l r}
   non-Archimedian axiom & $\forall a,b \in {\bf K},$ & $\phi(a+b) \le \max(\phi(a), \phi(b))$ &(V4')\cr
\end{supertabular}
\end{center}

In this case, we can switch from a multiplicative to an additive
notation and obtain {\it exponential valuation} by replacing $\phi(a)$
with $w(a) = -\ln \phi(a)$:

\begin{center}
\begin{supertabular}{l l l r}
   & $\forall a \in {\bf K},$ & $w(a) \in (-\infty, \infty]$ &(E1)\cr
   & $\forall a \in {\bf K},$ & $w(a) = \infty \Longleftrightarrow a = 0$ &(E2)\cr
   & $\forall a,b \in {\bf K},$ & $w(ab) = w(a) + w(b)$ &(E3)\cr
   & $\forall a,b \in {\bf K},$ & $w(a+b) \ge \min(w(a), w(b))$ &(E4)\cr
\end{supertabular}
\end{center}

\vfill\eject
\mysection{Notes on Harris - Geometry of Alg Curves - Harvard 287}

Abel's theorem -- p. 29

Classical Jacobian discussed on pp. 28-31

``As we've defined it, the Jacobian is only a complex torus so far. Note that a
general complex torus is not embeddable in projective space. However, it turns
out that the Jacobian has enough meromorphic functions to embed in projective
space, so it is a projective variety.''


\vfill\eject
\mysection{Notes on [Fu08]}

\cite{fulton} is a good, freely available introduction to algebraic geometry.

{\bf \cite{fulton} assumes an algebraically closed coefficient field throughout
(except Chapter 1).}

{\small\begin{verbatim}


Riemann-Roch Theorem

Let C be an algebraic curve, let X be its non-singular model, and let
K be its function field.

Proposition 8.4.  Let x \in K, x \notin k. Let (x)_0 be the divisor
of zeros of x and let n=[K:k(x)].  Then

  1) (x)_0 is an effective divisor of degree n,
  2) There is a constant \tau such that l(r(x)_0) \ge rn-\tau \forall r.

Proof

Prop 6.9. K is an algebraic function field in one variable over k.  By
definition, this means that exists some t such that K is algebraic
over k(t).  So x \in K is algebraic over k(t), and \exists F \ in
k[X,T] such that F[x,t] = 0.  x is not algebraic over k (1-48), so t
must appear in F, so t is algebraic over k(x), and therefore k(x,t) is
algebraic over k(x) (1-50), so K is algebraic over k(x) (1-46).



Problem 1-54: If R is a domain with quotient field K, and L is a
finite algebraic extension of K, then there exists a basis for L over
K such that each basis element is integral over R.

Proof 1-54: Let {w_1, ..., w_n} be any basis for L over K.  Since each
basis element is algebraic over K, by clearing denominators we can
write:

a_{i0} w_i^{n_i} + a_{i1} w_{n_i-1} + \cdots = 0       a_{ij} \in R

We can pull a_{i0} into w_i, and thus adjust the w_i's to be integral
over R by multiplying each one by something in R.  Since anything
in L can be written

   l = \sum c_i w_i        c_i \in K

it can also be written

   l = \sum (c_i / r_i) w'_i

where the r_i adjust the w_i to be integral and c_i/r_i is still in K.



INTEGRAL ELEMENTS: w integral over k[x] means that w is finite
everywhere x is, and has poles only where x does.  w integral over
k[x^{-1}] means that w is finite everywhere x^{-1} is, and has poles
only where x has zeros.

So, k[x^{-1}] is a domain with quotient field k(x), and K is a finite
algebraic extension of k(x), so there exists a basis for K over k(x)
such that each basis element is integral over k[x^{-1}].

Let {w_1, ..., w_n} be such a basis for K over k(x).  We will show
that the poles of these functions must lie over the roots of x.

w_i^{n_i} + a_{i1} w_{n_i-1} + \cdots = 0       a_{ij} \in k[x^{-1}]

So, ord_P(a_ij) \ge 0 if P \ne S (zero set of x), since x^{-1} and
thus anything in k[x^{-1}] is finite away from S.



Problem 2-29: if for some i, ord(a_i) < ord(a_j) \forall j \ne i,
then a_1 + \cdots + a_n \ne 0

Proof of 2-29: Assume the contrary.  Then we can write a_i =
\sum_{i\ne j} a_j.  Taking ord of both sides, and using ord(a+b) \ge
min(ord(a), ord(b)), we see this is impossible.



Therefore, ord_P(w_i) \ge 0 if P \ne S, since otherwise
ord_P(w_i^{n_i}) < ord_P(a_ij w^{n_i-j}) \forall j.

Therefore, the poles of w_i are isolated at the zeros of x, and since
there are only a finite number of w_i and each has a finite number of
poles, then for some t, div(w_i) + tZ > 0 \forall i.

So w_i \in L(tZ), and if j \le r, then w_i x^{-j} \in L((r+t)Z)

Now w_i are independent over k(x) and 1, x^{-1}, ..., x^{-r} are
independent over k, so l((r+t)Z) \ge n(r+1).

Now, l((r+t)Z) = l(rZ) + dim(L((r+t)Z) / L(rZ))

dim(L((r+t)Z) / L(rZ)) \le tm (Prop 3-1), where m is the degree of Z.

So, l(rZ) \ge n(r+1) - tm, so pick \tau = tm-n, and

l(rZ) \ge nr - \tau, \forall r




Riemman-Roch

l(D) = deg(D) + 1 - g + l(W-D)

deg(W) = 2g-2    l(W) = g

l(0) = 1

l(D) = 0 if deg(D) < 0

If deg(D) > 2g-2, then l(D) = deg(D) + 1 - g

If deg(D) = 2g-2, then deg(W-D) = 0, and l(W-D) = 1 iff D-W is principal, otherwise l(W-D) = 0

Let D=W+X, where deg(X)=0, then l(D) = 2g-2 + 1 - g + (1/0) depending on whether X is principal
   l(D) = g (X is principal) or l(D) = g - 1 (X is not principal)


Goal: an g-dimensional algebraic variety that represents Pic0

Consider (2g-2)-dimensional symmetric space.  Each point corresponds to an effective
divisor of degree (2g-2).

Fix a (g-2)-tuple.  We're left with g free points.


Milne's construction

Use r-dimensional symmetric space, with r > 2g-2.  Pick an (r-g) tuple.

\end{verbatim}
}

\vfill\eject
\mysection{Notes on [Sh61]}

{\small\begin{verbatim}

A function (Y -> k) is regular at a point on a variety if there exists
an open neighborhood of the point where the function is given by a
rational function of polynomials, the denominator never zero.
(relation to coordinate ring?)

A map (Y -> k) is regular on Y if it is regular at every point of Y.

A morphism (X -> Y) between varieties is a continuous map (in the
Zariski topology) such that pullbacks of regular functions are
regular.

A rational map is a morphism defined only on an open subset.

Given a rational map from affine varieties X to Y, if [x,y,z] is Y's
coordinate system, then we pullback to a regular function, which is a
rational function in X's function field.  So Y's coordinates are given
by rational functions in X's coordinates.

A group variety is an algebraic variety equipped with a group
structure, where the group operation and group inversion are rational
maps.  If the group operation is commutative, it's an abelian variety.

A homomorphism between abelian varieties is a rational map that
commutes with the group operation.

An endomorphism is a homomorphism from the variety to itself.

Endomorphisms of a group form a ring.  Addition is performed by
mapping through both endomorphisms, then applying the group operation,
which is commutative, so endomorphism addition is commutative.
Multiplication is performed by composition, and need not be
commutative.

Using just the addition structure, we get an abelian group that can be
structued as a Z-module.  Multiplication by an integer is just
repeated application of the endomorphism.

We can promote the endomorphism ring into an algebra by tensoring with
Q, call this EndQ(A).  Elements of EndQ(A) are basically endomorphisms
with an associated 1/n denominator (numerators can be sucked into the
endomorphism).

A lattice is a free Z-module of the same rank as the algebra over Q.

An order is a lattice that is also a subring and contains the identity.

The order of A, written t, is the image of the endomorphism ring in
the endomorphism algebra.

a is a lattice in the endomorphism algebra contained in t, so it's a
collection of actual endomorphisms.

g(a,A) is the set of points on A mapped to 0 by every element of a.

Prop 16. Let a be an integral ideal (p. 49) of F.  Reduction mod p
defines a homomorphism of g(a,A) onto g(a,A^).  If a is prime to the
characteristic of k^, this homomorphism is an isomorphism.


Div(C) is group of divisors
Div0(C) is group of degree 0 divisors
P(C) is group of principal divisors

P(C) in Div0(C) in Div(C)

define Pic(C) = Div(C)/P(C)
define Pic0(C) = Div0(C)/P(C)

Pic0(C) is isomorphic to the Jacobian variety with a point O.

Given a degree zero divisor in Div0(C), we can use the group law on
the Jacobian to construct a single point corresponding to the divisor.
Asking if the divisor is principal is asking if this point is O.
Asking if any multiple of the divisor is principal is asking if any
multiple of this point is O.

We can define an endomorphism to be addition by a point, using the
group law.  NO - doesn't take identity to identity.

Let's consider [n], the endomorphism defined by applying the group
operation n times (n is an integer).  This should generate a lattice
contained in t, so it's an integral ideal.  g([n], A) is the set of
points whose n-multiples are principal.

Given a divisor whose (k p^q)-multiple is principal, let's multiply by
p^q and get a divisor whose k-multiple is principal.  Endomorphism
ideal [k] is prime to p.  Then this divisor point will be in g(a,A)
and g(a,A^), where a is [k].

We can determine that the divisor point is in g(a,A^) for a=[k] by
determining that the divisor's k-multiple is principal on the module
curve.  Since this is an isomorphism, the divisor point is also in
g(a,A) for a=[k].




Given a non-singular algebraic curve C, we reduce mod p to get Cp.
Good reduction implies that Cp is non-singular with the same genus.  C
has an associated Jacobian J.  Cp also has an associated Jacobian Jp.

PROBLEM: (hopefully) Show that J mod p is Jp.

Construct J as follows.  Pick r > 2g-2.  Symmetric group J^(r).  Pick
r-g extra points and find an open covering of J^(r).  Within each
open set, construct J locally.

\end{verbatim}
}

\vfill\eject
\mysection{Function Fields (Stichtenoth)}

Stichtenoth, ``Algebraic Function Fields and Codes''.

Let $K$ be a field.

$F/K$ is called {\it rational} if $F=K(x)$ for some $x \in F$

A valuation ring of a function field $F/K$ is a ring $O \in F$ such that
   $K \in O \in F$ (both proper inclusions)
   for every $z \in F$, either $z \in O$ or $z^{-1} \in O$

For the rational function field $K(x)$, there's a valuation ring for each
irreducible polynomial

A place of a function field $F/K$ is the unique maximal ideal of a valuation ring $O$ of $F/K$.

Every element of $t \in P$ such that $P = t O$ is called a prime element, or
local paramter, or uniformizing variable of $P$).

$P$ determines $O$ uniquely.  $O_P$ is called the valuation ring of the place $P$

Definition 1.4.1 - a divisor is a formal sum over the places of $F/K$

\vfill\eject
\mysection{The Riemann-Roch Theorem}

Various proofs of the Riemann-Roch Theorem:

Fulton (Chapter 8) - uses nonsingular model of curve

Milne (Theorem 14.6) - assumes curve is nonsingular

Stichtenoth - constructs divisor using places (Cartier divisor)

Vakil (Eq 18.4.2.1) - unclear to me if he assumes regularity

\mysection{Examples}

\example Compute $\int \sqrt{4-x^2} \,dx$

A solution method from first year calculus might be to note that
this integrand forms one leg of a right triangle:

\begin{center}
\setlength{\unitlength}{1cm}
\begin{picture}(6,5)
\put(5,1){\line(0,1){3}}
\put(5,1){\line(-1,0){4}}
\put(1,1){\line(4,3){4}}
\put(2.5,0.5){$\sqrt{4-x^2}$}
\put(3,2.8){2}
\put(5.2,2.5){$x$}
\put(1.7,1.15){$\theta$}
\end{picture}
\end{center}

$$x=2\sin\theta \qquad \sqrt{4-x^2}=2\cos\theta \qquad dx=2\cos\theta\,d\theta$$


\begin{eqnarray*}
\int \sqrt{4-x^2} \, dx & = & \int 4 \cos^2\theta \, d\theta \\
& = & \int \left( 2 + 2\cos 2\theta \right) \, d\theta \\
& = & 2\theta + \sin 2\theta \\
& = & 2\theta + 2\sin\theta\cos\theta \\
& = & 2\arcsin\frac{x}{2} + \frac{x \sqrt{4-x^2}}{2} \\
\end{eqnarray*}

Now let's attack this integral using the methods of this chapter.
First, transform the problem into an algebraic curve:

$$\int y\,dx \qquad y^2 = 4-x^2$$

Since $\lim_{x\to\infty} y = \infty$, the integrand has poles at
infinity.  We want infinity to be an ordinary point of the curve (no
ramification; no singularities) with no poles in the integrand.  The
simplest transformation is to exchange zero with infinity, and in this
case zero is an ordinary point with places $(0,2)$ and $(0,-2)$,
neither of which is a pole of the integrand.  So we'll invert
$x$ and $y$ into $u$ and $v$:

$$x=\frac{1}{u} \qquad y=\frac{1}{v}$$
$$\left(\frac{1}{v}\right)^2 = 4 - \left(\frac{1}{u}\right)^2 \Longrightarrow 4u^2v^2 - v^2 - u^2=0$$
$$\int\frac{1}{v} \, d\left(\frac{1}{u}\right) \Longrightarrow -\int\frac{1}{vu^2}\,du$$

The only poles in this integrand occur when either $u=0$ or $v=0$.
Substituting these values into $4u^2v^2 - v^2 -u^2=0$, we see that
these condiutions only occur at $(u,v)=(0,0)$, so let's analyze our
curve at that point, starting with the Newton polygon:

\begin{center}
$4 u^2 v^2 - v^2 - u^2 = 0$ \\
\setlength{\unitlength}{1cm}
\begin{picture}(3,3)
\put(0,0){\line(0,1){2.5}}
\put(0,0){\line(1,0){3}}
\put(1.9,-0.1){x}
\put(1.9,1.9){x}
\put(-0.1,1.9){x}
\thicklines
\put(0,2){\line(1,-1){2}}
\end{picture}
\end{center}

The Newton polygon has a single line segment of span 2 and slope -1, so
we have two cycles, each with ramification index one: a singularity.
Since there is no ramification, $u$ is a uniformizing parameter
and we expect to expand $v$ as follows:

$$v = c_1 u + c_2 u^2 + c_3 u^3 + \cdots$$
$$v^2 = c_1^2 u^2 + 2 c_1 c_2 u^3 + (2 c_1 c_3 + c_2^2) u^4 + \cdots$$

Substituting these expansions into $4u^2v^2 - v^2 - u^2 = 0$, we obtain:

$$ 4 c_1^2 u^4 + 8 c_1 c_2 u^5 + (8 c_1 c_3 + 4 c_2^2) u^6 + \cdots $$
$$ - c_1^2 u^2 - 2 c_1 c_2 u^3 - (2 c_1 c_3 + c_2^2) u^4 + \cdots - u^2 = 0$$

Equating terms in $u^2$, we see that $c_1 = \pm i$.  Each of these
two values corresponds to one branch of the singularity.  There
is only a single term in $u^3$, which forces $c_2$ to be zero,
and equating terms in $u^4$ produces $c_3 = 2 c_1$, so

$$v = \pm (iu + 2iu^3 + \cdots) \qquad @(0,0)$$

Inverting $v$ and substituting into our 1-form, we obtain

$$\frac{1}{v} = \pm (-i \frac{1}{u} + 2i u + \cdots) \qquad @(0,0)$$

$$\frac{1}{vu^2}\, du = \pm \left[ -i \frac{1}{u^3} + 2i \frac{1}{u} + \cdots \right] \, du \qquad @(0,0)$$

The $u^{-1}$ terms will integrate into logarithms, so let's ignore
them for the moment and concentrate on the $u^{-3}$ terms, which will
integrate into $u^{-2}$ terms, so we're looking for a function with
second order poles at both places at the $(0,0)$ singularity.

Starting with our standard basis for all rational functions,
$\{1,\,v\}$, we seek to modify it into a basis for
${\rm P}^2(0,0)_a{\rm P}^2(0,0)_b$.  Note first that $v$ has
poles at $u=\pm\frac{1}{2}$.  Using $y=1/u$, we analyze
at $(\pm\frac{1}{2}, \infty)$ as follows:

\begin{center}
$y^2\left[(u-\frac12)^2+(u-\frac12)+\frac14\right]-4(u-\frac12)^2-4(u-\frac12)$
\\
\setlength{\unitlength}{1cm}
\begin{picture}(3,3)
\put(0,0){\line(0,1){2.5}}
\put(0,0){\line(1,0){3}}
\put(0.9,-0.1){x}
\put(1.9,-0.1){x}
\put(-0.1,1.9){x}
\put(0.9,1.9){x}
\put(1.9,1.9){x}
\thicklines
\put(0,2){\line(1,-2){1}}
\end{picture}
\end{center}

Our line segment has span 1 and slope -2, indicating a single place
with ramification 2, and $y$ as a uniformizing parameter.  Setting

$$(u-\frac12) = c_1 y + c_2 y^2 + \cdots$$
$$(u-\frac12)^2 = c_1^2 y^2 + \cdots$$

Substituting, we find that $c_1 = 0$ and $c_2 = \frac{1}{16}$, so

$$(u-\frac12) = \frac{1}{16} y^2 + \cdots \qquad v=y^{-1} \qquad @(\frac12, \infty)$$

$$(u+\frac12) = \frac{1}{16} y^2 + \cdots \qquad v=y^{-1} \qquad @(-\frac12, \infty)$$

In short, $v$ has first order poles at $(\pm\frac12,\infty)$ and
$(u\pm\frac12)$ has second order zeros, so we can adjust our basis
accordingly and obtain $\{1,\,(4u^2-1)v\}$ for a basis with no finite
poles.  We can also use a theorem of Trager to shortcut this calculation.

Returning to our analysis at $(0,0)$, we see that 1 has zero order
(obviously) and $(4u^2-1)v$ has a first order zero at both sheets
there, since $4u^2-1=-1$ is finite and $v$ has first order zeros.
We also know that $u$ is a uniformizing parameter, so it's easy
to modify our basis and obtain

$$\left\{\frac{1}{u^2},\,\frac{4u^2-1}{u^3}v\right\} {\rm is\, a\,} {\bf C}[x]{\rm -basis\, for\, P^2(0,0)_aP^2(0,0)_b}$$

Is this basis normal at infinity?  Well, the representation order of
$\frac{1}{u^2}$ is 2 and its $u^-2$ coefficients at $(\infty, \pm
\frac12)$ are both 1, while the representation order of $\frac{4u^2-1}{u^3}v$
is 1, and its $u^-1$ coefficients are 2 and -2.  Since

$$\det C = \begin{array}{|cc|} 1 & 2 \\ 1 & -2 \end{array} = -4$$

is non-zero, the basis is normal at infinity.

The Riemann-Roch theorem says that the dimension of ${\mathfrak l}(D)$ is 5,
$\frac{1}{u^2}$ can be multiplied by any polynomial up to second
degree without introducing poles at infinity, and $\frac{4u^2-1}{u^3}v$
can be multiplied by any polynomial up to first degree, so

$$\left\{\frac{1}{u^2},\, \frac{1}{u},\, 1,\, \frac{4u^2-1}{u^3}v,\, \frac{4u^2-1}{u^2}v\right\}$$

is a ${\cal C}$-module basis for ${\mathfrak l}(D)$.

Any linear combination of these functions is a multiple of the
divisor, but not all of them produce the correct residues.  Looking at
the residues, we see that only $\frac{4u^2-1}{u^3}v = \frac{1}{uv}$
has residues of $\pm i$ on the two sheets at the $(0,0)$ singularity.
Dividing by 2 to correct for the 2 that will be introduced by the
integration, we conclude that $\frac{1}{2uv} = \frac{xy}{2} =
\frac{x\sqrt{4-x^2}}{2}$ is the desired function.

Next, we have to deal with the logarithms.  Going back to the
series expansions of our 1-form, we see that we have residues
of $\pm 2i$ on our two sheets at $(0,0)$.  The objective
now is a bit different; we want a function with exactly
the divisor $Z(0,0)_a P(0,0)_b$.  Starting with an integral basis:

$$\{1, (4u^2-1)v\}$$

we want to modify these functions to make them multiples
of $Z(0,0)_a P(0,0)_b$.  The pole isn't a problem for
an integral basis, and looking at the series expansion
for $v$ at $(0,0)$ we see that it (and therefore $(4u^2-1)v$)
has a simple zero there, but $1$ needs to be replaced with $u$:

$$\{u, (4u^2-1)v\}$$

Now we construct a matrix with the coefficients in the series expansions:

$$\left[ \begin{array}{cc} 1 & -i \\ 0 & 0 \end{array} \right] \begin{array}{ll} \leftarrow (0,0)_a \\ \leftarrow (0,0)_b \end{array} $$

$$\left[ \begin{array}{cc} 1 & -i \\ 0 & 0 \end{array} \right] \left[ \begin{array}{c} i \\ 1 \end{array} \right] = 0$$

The solution shows us how to modify the basis:

$$\{u, \frac{iu + (4u^2-1)v}{u}\} = \{u, i + \frac{(4u^2-1)v}{u}\}$$

$$\left[ \begin{array}{cc} 1 & 0 \\ 0 & 0 \end{array} \right] \begin{array}{ll} \leftarrow (0,0)_a \\ \leftarrow (0,0)_b \end{array} $$

$$\left[ \begin{array}{cc} 1 & 0 \\ 0 & 0 \end{array} \right] \left[ \begin{array}{c} 0 \\ 1 \end{array} \right] = 0$$

$$\{u, i\frac{1}{u} + \frac{(4u^2-1)v}{u^2}\}$$

$$\left| \begin{array}{cc} 1 & -2i \\ 0 & 2i \end{array} \right| = 2i$$

At the last step, the determinant is non-zero, which shows that we
now have a basis for multiples of the divisor except at infinity.
Is it normal at infinity?  $u$'s expansion at both places at infinity
is $\left(\frac{1}{u}\right)^{-1}$, so its representation order is -1,
and the second element's expansion at infinity starts $\pm 2 + \cdots$,
so its representation order is 0 and:

$$\det C = \begin{array}{|cc|} 1 & 2 \\ 1 & -2 \end{array} = -4$$

So the basis is normal at infinity.  If an exact multiple of
the divisor exists, it is one of the basis elements.  It's not $u$,
since $u$ has a pole at infinity, but the second element is exact:

$$i\frac{1}{u} + \frac{(4u^2-1)v}{u^2} = i\frac{1}{u} - \frac{1}{v} = ix-y$$

The desired residues are $\pm 2i$, so the function we want is

$$2i \ln(ix-y) = 2i \ln(\frac{y}{2}-i\frac{x}{2}) + 2i \ln(-2) $$
$$= 2i \ln\left(\sqrt{1-\left(\frac{x}{2}\right)^2} - i\frac{x}{2}\right) = 2i (-i \arcsin \frac{x}{2}) = 2 \arcsin \frac{x}{2}$$

(the constant disappears into the constant of integration) and the final answer is:

$$ \int \sqrt{4-x^2} \, dx  = 2\arcsin\frac{x}{2} + \frac{x \sqrt{4-x^2}}{2}$$

\endexample


\vfill\eject
\mysection{arcsin}

\example Compute $\int {1\over{\sqrt{1-x^2}}} \,dx$

The obvious attempt is to use the algebraic extension $y^2=1-x^2$ and
integrate ${1\over y}\,dx$.

But we first need to determine if this differential has any poles at
infinity, by inverting the field and looking for poles at zero.
Setting $u={1\over x}$, we convert our minimal polynomial into
$u^2y^2=u^2-1$ (after multiplying through by $u^2$), and using
$v=uy$ we obtain our inverse field ${\bf C}(u,v); v^2=u^2-1$.

Since $x={1\over u}$ and $y={v\over u}$, we convert our differential as follows:

 $${1\over y}\,dx ={u\over v} (-{1\over{u^2}} \, du) = -{1\over{uv}} \, du$$

Now, $\{1, v\}$ is an integral basis for the inverse field, so we
multiply through by $v\over v$ to obtain:

 $$= -{v\over{uv^2}} du = -{1\over{u(u^2-1)}}v \, du $$

which is now in normal form and clearly has a pole at $u=0$, or $x=\infty$.  Note that

 $${1\over y} = {u\over v} = {{uv}\over{v^2}}
 = {u\over{u^2-1}} v$$

has no pole at $u=0$, a clear example of a differential having a pole
at a place where its constituent function has none.

In any event, we clearly can not use the original field to conduct the
integration, since it would require constructing a function with a
pole at infinity, and our algorithm can't handle this.  So we need to
transform into a field where the differential has no pole at infinity.

Actually, we've already done this!  Note that the integrand had no pole
at zero in the original field:

 $${1\over y}\,dx = {y\over y^2}\,dx = {1\over{1-x^2}}y \,dx $$

Since the inverse field swapped zero with infinity, it follows that
there is no pole at infinity in the inverse field, so we can proceed
to integrate $-{1\over{u(u^2-1)}}v \,du$ in ${\bf C}(u,v)$;
$v^2=u^2-1$.

Simple inspection of the integrand (already in normal form) shows that
its poles are at $(0, i)$, $(0, -i)$, $(1, 0)$, and $(-1, 0)$.
Remember that we're now working on the Riemann surface of an algebraic
extension, so we need to specify $\it both$ $u$ and $v$ to
specify a place.

The next step is to compute the residues at each of these places,
using Theorem \ref{Trager's residue theorem}:

\begin{center}
\begin{supertabular}{l l l}
  $(0, i)$  &  $\displaystyle -{1\over{(u^2-1)}}v$ @ $(0, i)$     & = $i$    \cr
  $(0, -i)$  &  $\displaystyle -{1\over{(u^2-1)}}v$ @ $(0, -i)$   & = $-i$    \cr
  $(1, 0)$  &  $\displaystyle -2{1\over{u(u+1)}}v$ @ $(1, 0)$      & = $0$    \cr
  $(-1, 0)$  &  $\displaystyle -2{1\over{u(u-1)}}v$ @ $(-1, 0)$    & = $0$    \cr
\end{supertabular}
\end{center}

The poles with zero residues can be ignored.  We're interested in the
other two, which exist in ${\bf Q}[i]$, which can be regarded as a
vector field over ${\bf Q}$ with basis $\{1, i\}$, and we want to
construct a function whose poles and zeros match the $i$-component of
the residues (the 1-component is uniformly zero).

We start by constructing an ${\cal I}$-module generator set for the divisor
with a simple zero at $(0,i)$ and a simple pole at $(0,-i)$.  Theorem
\ref{simple pole construction} shows that:

$$f = {{v^2+1}\over{u(v+i)}} = {{v-i}\over{u}} $$

has a simple pole at $(0,-i)$.  At $(0,i)$, L'H\^opital's rule gives:

$$ \lim_{(u,v)\to (0,i)} {{v-i}\over{u}}
   = {{(v-i)'}\over{u'}} {{dv}\over{du}} = {{dv}\over{du}} = {u\over v} = 0 $$

where the last transformation was accomplished by differentiating the
mimimal polynomial.  So $f$ has a zero at $(0,i)$, and I'll note that
we've just stumbled into the solution.  Theorem \ref{simple pole
construction} already assures us that $f$ has only a single finite
simple pole, and we can see that its only zeros occur when
$v-i=0$, which, according to the minimum polynomial, can only
occur at $u=0$, thus $(0,i)$ is its only finite zero, and it is
simple, as we can verify by showing that the corresponding pole in its
inverse is simple:

$$ {1\over f} = {u\over{v-i}} = {{u(v+i)}\over{v^2+1}}
  = {{u(v+i)}\over{u^2}} = {1\over u}v + {i\over u} $$


So we've found the function we're looking for by accident.  Let's save the
general case for the next example, and convert back to
our original field:

$${{v-i}\over{u}} = x({y\over x}-i) = y - ix $$

Remembering that our residues came multiplied by a factor of $i$, we
conclude that our solution is $i\,\ln(y-ix)$, or:

\begin{eqnarray*}
\int {1\over{\sqrt{1-x^2}}} \,dx &=& i\,\ln(\sqrt{1-x^2}-ix) \\
                                 &=& -i\,\ln({1\over{\sqrt{1-x^2}-ix}}) \\
                                 &=& -i\,\ln({{\sqrt{1-x^2}+ix}\over{1-x^2+x^2}}) \\
                                 &=& -i\,\ln({\sqrt{1-x^2}+ix}) \\
                                 &=& \arcsin x \\
\end{eqnarray*}

where I used the negative of a logarithm being the logarithm of the
inverse, and the last transformation came from section
\ref{sec:Liouvillian Forms}.


\endexample
